{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lavaILXgTTl0"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/giordamaug/HELP/blob/main/help/notebooks/prediction.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n",
        "<a target=\"_blank\" href=\"https://www.kaggle.com/notebooks/welcome?src=https://github.com/giordamaug/HELP/blob/main/help/notebooks/prediction.ipynb\">\n",
        "  <img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joeFb6T-TTl3"
      },
      "source": [
        "# Install HELP from GitHub\n",
        "Skip this cell if you already have installed HELP."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tuF0S73STTl4",
        "outputId": "e6d33ca9-a106-46fe-df06-3f8c3075441f"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/giordamaug/HELP.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFrBvM5ErPN4"
      },
      "source": [
        "# Download the input files\n",
        "In this cell we download from GitHub repository the label file and the attribute files. Skip this step if you already have these input files locally."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wbcOjf7TTl5",
        "outputId": "350746d3-7293-4f67-cc3a-7295acbfa022"
      },
      "outputs": [],
      "source": [
        "tissue='Kidney'\n",
        "!wget https://raw.githubusercontent.com/giordamaug/HELP/main/help/datafinal/{tissue}_HELP.csv\n",
        "!wget https://raw.githubusercontent.com/giordamaug/HELP/main/help/datafinal/{tissue}_BIO.csv\n",
        "for i in range(5):\n",
        "  !wget https://raw.githubusercontent.com/giordamaug/HELP/main/help/datafinal/{tissue}_CCcfs_{i}.csv\n",
        "!wget https://raw.githubusercontent.com/giordamaug/HELP/main/help/datafinal/{tissue}_EmbN2V_128.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/maurizio/HELP/data\n"
          ]
        }
      ],
      "source": [
        "%cd ../../data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqSGGzfNTTl6"
      },
      "source": [
        "# Process the tissue attributes\n",
        "In this code we load tissue gene attributes by several datafiles. We apply missing values fixing and data scaling with `sklearn.preprocessing.StandardScaler` on the `BIO` and `CCcfs` attributes, while no normalization and fixing on embedding attributes (`EmbN2V_128`). The attributes are all merged in one matrix by the `feature_assemble` function as input for the prediction model building."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        },
        "execution": {
          "iopub.execute_input": "2024-02-13T11:09:02.545717Z",
          "iopub.status.busy": "2024-02-13T11:09:02.545238Z",
          "iopub.status.idle": "2024-02-13T11:09:16.557744Z",
          "shell.execute_reply": "2024-02-13T11:09:16.556982Z",
          "shell.execute_reply.started": "2024-02-13T11:09:02.545678Z"
        },
        "id": "toAayH83TTl7",
        "outputId": "25f23ce9-ac16-4ecc-95ee-8153c74656d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label\n",
            "NE       16678\n",
            "E         1253\n",
            "dtype: int64\n",
            "Majority NE 16678 minority E 1253\n",
            "[Kidney_BIO.csv] found 52532 Nan...\n",
            "[Kidney_BIO.csv] Normalization with std ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading file in chunks: 100%|██████████| 5/5 [00:09<00:00,  1.99s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Kidney_CCcfs.csv] found 6676644 Nan...\n",
            "[Kidney_CCcfs.csv] Normalization with std ...\n",
            "[Kidney_EmbN2V_128.csv] found 0 Nan...\n",
            "[Kidney_EmbN2V_128.csv] No normalization...\n",
            "17236 labeled genes over a total of 17931\n",
            "(17236, 3456) data input\n"
          ]
        }
      ],
      "source": [
        "tissue='Kidney'\n",
        "import pandas as pd\n",
        "from help.preprocess.loaders import feature_assemble_df\n",
        "import os\n",
        "df_y = pd.read_csv(f\"{tissue}_HELP.csv\", index_col=0)\n",
        "df_y = df_y.replace({'aE': 'NE', 'sNE': 'NE'})\n",
        "print(df_y.value_counts(normalize=False))\n",
        "features = [{'fname': f'{tissue}_BIO.csv', 'fixna' : False, 'normalize': 'std'},\n",
        "            {'fname': f'{tissue}_CCcfs.csv', 'fixna' : False, 'normalize': 'std', 'nchunks' : 5},\n",
        "            {'fname': f'{tissue}_EmbN2V_128.csv', 'fixna' : False, 'normalize': None}]\n",
        "df_X, df_y = feature_assemble_df(df_y, features=features, saveflag=False, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import *\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from collections import Counter\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from tqdm import tqdm\n",
        "from tabulate import tabulate\n",
        "from typing import List,Dict,Union,Tuple\n",
        "def set_seed(seed=1):\n",
        "    \"\"\"\n",
        "    Set random and numpy random seed for reproducibility\n",
        "\n",
        "    :param int seed: inistalization seed\n",
        "\n",
        "    :returns None.\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "def predict_cv_(X, Y, n_splits=10, method='LGBM', method_args = {}, balanced=False, saveflag: bool = False, outfile: str = 'predictions.csv', verbose: bool = False, display: bool = False,  seed: int = 42):\n",
        "    \"\"\"\n",
        "    Perform cross-validated predictions using a LightGBM classifier.\n",
        "\n",
        "    :param DataFrame X: Features DataFrame.\n",
        "    :param DataFrame Y: Target variable DataFrame.\n",
        "    :param int n_splits: Number of folds for cross-validation.\n",
        "    :param str method: Classifier method (default LGBM)\n",
        "    :param bool balanced: Whether to use class weights to balance the classes.\n",
        "    :param bool saveflag: Whether to save the predictions to a CSV file.\n",
        "    :param str or None outfile: File name for saving predictions.\n",
        "    :param bool verbose: Whether to print verbose information.\n",
        "    :param bool display: Whether to display a confusion matrix plot.\n",
        "    :param int or None seed: Random seed for reproducibility.\n",
        "\n",
        "    :returns: Summary statistics of the cross-validated predictions, single measures and label predictions\n",
        "    :rtype: Tuple(pd.DataFrame,pd.DataFrame,pd.DataFrame)\n",
        "\n",
        "    :example:\n",
        " \n",
        "    .. code-block:: python\n",
        "\n",
        "        # Example usage\n",
        "        X_data = pd.DataFrame(...)\n",
        "        Y_data = pd.DataFrame(...)\n",
        "        result, _, _ = predict_cv(X_data, Y_data, n_splits=5, balanced=True, saveflag=False, outfile=None, verbose=True, display=True, seed=42)\n",
        "    \"\"\"\n",
        "    methods = {'LGBM': LGBMClassifier, 'SV': VotingSplitClassifier}\n",
        "\n",
        "    # silent twdm if no verbosity\n",
        "    #if not verbose: \n",
        "    #    def notqdm(iterable, *args, **kwargs): return iterable\n",
        "    #    tqdm = notqdm\n",
        "    # get the list of genes\n",
        "    genes = Y.index\n",
        "\n",
        "    # Encode target variable labels\n",
        "    encoder = LabelEncoder()\n",
        "    X = X.values\n",
        "    y = encoder.fit_transform(Y.values.ravel())\n",
        "\n",
        "    # Display class information\n",
        "    classes_mapping = dict(zip(encoder.classes_, encoder.transform(encoder.classes_)))\n",
        "    if verbose: print(f'{classes_mapping}\\n{Y.value_counts()}')\n",
        "\n",
        "    # Set random seed\n",
        "    set_seed(seed)\n",
        "\n",
        "    # Initialize StratifiedKFold\n",
        "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
        "\n",
        "    # Initialize classifier\n",
        "    #clf = LGBMClassifier(class_weight='balanced', verbose=-1) if balanced else LGBMClassifier(verbose=-1)\n",
        "    clf = methods[method](**method_args)\n",
        "\n",
        "    nclasses = len(np.unique(y))\n",
        "    mm = np.array([], dtype=np.int64)\n",
        "    gg = np.array([])\n",
        "    yy = np.array([], dtype=np.int64)\n",
        "    predictions = np.array([], dtype=np.int64)\n",
        "    probabilities = np.array([])\n",
        "\n",
        "    # Columns for result summary\n",
        "    columns_names = [\"ROC-AUC\", \"Accuracy\", \"BA\", \"Sensitivity\", \"Specificity\", \"MCC\", 'CM']\n",
        "    scores = pd.DataFrame()\n",
        "\n",
        "    if verbose:\n",
        "        print(f'Classification with {method}({method_args})...')\n",
        "\n",
        "    # Iterate over each fold\n",
        "    for fold, (train_idx, test_idx) in enumerate(tqdm(kf.split(np.arange(len(X)), y), total=kf.get_n_splits(), desc=f\"{n_splits}-fold\", disable=not verbose)):\n",
        "        train_x, train_y, test_x, test_y = X[train_idx], y[train_idx], X[test_idx], y[test_idx],\n",
        "        mm = np.concatenate((mm, test_idx))\n",
        "        probs = clf.fit(train_x, train_y).predict_proba(test_x)\n",
        "        preds = np.argmax(probs, axis=1)\n",
        "        gg = np.concatenate((gg, genes[test_idx]))\n",
        "        yy = np.concatenate((yy, test_y))\n",
        "        cm = confusion_matrix(test_y, preds)\n",
        "        predictions = np.concatenate((predictions, preds))\n",
        "        probabilities = np.concatenate((probabilities, probs[:, 0]))\n",
        "\n",
        "        # Calculate and store evaluation metrics for each fold\n",
        "        roc_auc = roc_auc_score(test_y, probs[:, 1]) if nclasses == 2 else roc_auc_score(test_y, probs, multi_class=\"ovr\", average=\"macro\")\n",
        "        scores = pd.concat([scores, pd.DataFrame([[roc_auc,\n",
        "                                                    accuracy_score(test_y, preds),\n",
        "                                                    balanced_accuracy_score(test_y, preds),\n",
        "                                                    cm[0, 0] / (cm[0, 0] + cm[0, 1]),\n",
        "                                                    cm[1, 1] / (cm[1, 0] + cm[1, 1]),\n",
        "                                                    matthews_corrcoef(test_y, preds),\n",
        "                                                    cm]],\n",
        "                                                  columns=columns_names, index=[fold])],\n",
        "                           axis=0)\n",
        "\n",
        "    # Calculate mean and standard deviation of evaluation metrics\n",
        "    df_scores = pd.DataFrame([f'{val:.4f}±{err:.4f}' for val, err in zip(scores.loc[:, scores.columns != \"CM\"].mean(axis=0).values,\n",
        "                                                                     scores.loc[:, scores.columns != \"CM\"].std(axis=0))] +\n",
        "                             [(scores[['CM']].sum()).values[0].tolist()],\n",
        "                             columns=['measure'], index=scores.columns)\n",
        "\n",
        "    # Display confusion matrix if requested\n",
        "    if display:\n",
        "        ConfusionMatrixDisplay(confusion_matrix=np.array(df_scores.loc['CM']['measure']), display_labels=encoder.inverse_transform(clf.classes_)).plot()\n",
        "\n",
        "    # Create DataFrame for storing detailed predictions\n",
        "    df_results = pd.DataFrame({'gene': gg, 'label': yy, 'prediction': predictions, 'probabilities': probabilities})\n",
        "    df_results = df_results.set_index(['gene'])\n",
        "\n",
        "    # Save detailed predictions to a CSV file if requested\n",
        "    if saveflag:\n",
        "        df_results.to_csv(outfile)\n",
        "\n",
        "    # Return the summary statistics of cross-validated predictions, the single measures and the prediction results\n",
        "    return df_scores, scores, df_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 1, 1, ..., 1, 1, 1])"
            ]
          },
          "execution_count": 159,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 202,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'E': 0, 'NE': 1}\n",
            "label\n",
            "NE       15994\n",
            "E         1242\n",
            "dtype: int64\n",
            "Classification with SV({'class_weight': 'balanced', 'n_voters': 10, 'verbose': True})...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "5-fold:   0%|          | 0/5 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Majority 1 12795, minority 0 993\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "10-voter: 100%|██████████| 10/10 [01:38<00:00,  9.87s/it]\n",
            "5-fold:  20%|██        | 1/5 [01:40<06:40, 100.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Majority 1 12795, minority 0 994\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "10-voter: 100%|██████████| 10/10 [01:39<00:00,  9.96s/it]\n",
            "5-fold:  40%|████      | 2/5 [03:21<05:02, 100.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Majority 1 12795, minority 0 994\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "10-voter: 100%|██████████| 10/10 [01:38<00:00,  9.88s/it]\n",
            "5-fold:  60%|██████    | 3/5 [05:01<03:21, 100.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Majority 1 12795, minority 0 994\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "10-voter: 100%|██████████| 10/10 [01:35<00:00,  9.58s/it]\n",
            "5-fold:  80%|████████  | 4/5 [06:38<01:39, 99.27s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Majority 1 12796, minority 0 993\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "10-voter: 100%|██████████| 10/10 [01:35<00:00,  9.56s/it]\n",
            "5-fold: 100%|██████████| 5/5 [08:16<00:00, 99.20s/it]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(                                  measure\n",
              " ROC-AUC                     0.9567±0.0046\n",
              " Accuracy                    0.8813±0.0038\n",
              " BA                          0.8893±0.0081\n",
              " Sensitivity                 0.8986±0.0137\n",
              " Specificity                 0.8800±0.0032\n",
              " MCC                         0.5285±0.0128\n",
              " CM           [[1116, 126], [1920, 14074]],\n",
              "     ROC-AUC  Accuracy        BA  Sensitivity  Specificity       MCC  \\\n",
              " 0  0.956731  0.879350  0.890538     0.903614     0.877462  0.527458   \n",
              " 1  0.964416  0.888019  0.902472     0.919355     0.885589  0.550750   \n",
              " 2  0.955886  0.879605  0.884921     0.891129     0.878712  0.521578   \n",
              " 3  0.952417  0.879896  0.886937     0.895161     0.878712  0.523972   \n",
              " 4  0.954117  0.879605  0.881417     0.883534     0.879300  0.518796   \n",
              " \n",
              "                          CM  \n",
              " 0  [[225, 24], [392, 2807]]  \n",
              " 1  [[228, 20], [366, 2833]]  \n",
              " 2  [[221, 27], [388, 2811]]  \n",
              " 3  [[222, 26], [388, 2811]]  \n",
              " 4  [[220, 29], [386, 2812]]  ,\n",
              "         label  prediction  probabilities\n",
              " gene                                    \n",
              " A2M         1           1       0.048046\n",
              " A2ML1       1           1       0.001259\n",
              " A4GNT       1           1       0.001800\n",
              " AAAS        1           0       0.968071\n",
              " AACS        1           1       0.008560\n",
              " ...       ...         ...            ...\n",
              " ZSCAN9      1           1       0.004045\n",
              " ZSWIM6      1           1       0.004886\n",
              " ZUP1        1           1       0.127405\n",
              " ZYG11A      1           1       0.011452\n",
              " ZZEF1       1           1       0.205910\n",
              " \n",
              " [17236 rows x 3 columns])"
            ]
          },
          "execution_count": 202,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predict_cv_(df_X, df_y, n_splits=5, method='SV', method_args = {'class_weight':'balanced', 'n_voters':10, 'verbose': True}, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 201,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.base import BaseEstimator, ClassifierMixin, RegressorMixin\n",
        "from lightgbm import LGBMClassifier \n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "class VotingSplitClassifier(BaseEstimator, ClassifierMixin):\n",
        "\n",
        "    def __init__(self, n_voters=10, verbose=False, **kwargs):\n",
        "        self.kwargs = kwargs\n",
        "        # intialize ensemble ov voters\n",
        "        self.verbose = verbose\n",
        "        self.n_voters = n_voters\n",
        "        self.estimators = [LGBMClassifier(random_state=42) for i in range(n_voters)]\n",
        "        pass\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        # Find the majority and minority class\n",
        "        assert isinstance(X, np.ndarray) and isinstance(y, np.ndarray), \"Only array input!\"\n",
        "        unique, counts = np.unique(y, return_counts=True)\n",
        "        minlab = unique[np.argmin(counts)]\n",
        "        maxlab = unique[np.argmax(counts)]\n",
        "\n",
        "        if self.verbose:\n",
        "            print(f\"Majority {maxlab} {max(counts)}, minority {minlab} {min(counts)}\")\n",
        "\n",
        "        # Separate majority and minority class\n",
        "        df_y_ne = np.where(y == maxlab)[0]\n",
        "        df_y_e = np.where(y == minlab)[0]\n",
        "\n",
        "        # Split majority class among voters\n",
        "        splits = np.array_split(df_y_ne, self.n_voters)\n",
        "        for i,df_index_ne in enumerate(tqdm(splits, desc=f\"{self.n_voters}-voter\", disable = not self.verbose)):\n",
        "            df_X = np.append(X[df_index_ne], X[df_y_e], axis=0)\n",
        "            df_y = np.append(y[df_index_ne], y[df_y_e], axis=0)\n",
        "            self.estimators[i].fit(df_X,df_y)\n",
        "        return self\n",
        "    \n",
        "    def predict_proba(self, X, y=None):\n",
        "        # Find the majority and minority class\n",
        "        assert isinstance(X, np.ndarray), \"Only array input!\"\n",
        "        probabilities = np.array([self.estimators[i].predict_proba(X) for i in range(self.n_voters)])\n",
        "        return np.sum(probabilities, axis=0)/self.n_voters\n",
        "    \n",
        "    def predict(self, X, y=None):\n",
        "        assert isinstance(X, np.ndarray), \"Only array input!\"\n",
        "        probabilities = np.array([self.estimators[i].predict_proba(X) for i in range(self.n_voters)])\n",
        "        return np.argmax(np.sum(probabilities, axis=0)/self.n_voters, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['NE', 'NE', 'NE', ..., 'NE', 'NE', 'NE'], dtype=object)"
            ]
          },
          "execution_count": 183,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_y.values.ravel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 194,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Majority NE 1242, minority E 15994\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "3-voter:   0%|          | 0/3 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "3-voter: 100%|██████████| 3/3 [01:02<00:00, 20.90s/it]\n"
          ]
        }
      ],
      "source": [
        "clf = VotingSplitClassifier(n_voters=3, class_weight='balanced', verbose=True)\n",
        "pp = clf.fit(df_X.values, df_y.values.ravel()).predict_proba(df_X.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(17236, 2)"
            ]
          },
          "execution_count": 196,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pp.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {},
      "outputs": [],
      "source": [
        "pp = clf.predict_proba(df_X.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([    7,    14,    16, ..., 17225, 17226, 17227])"
            ]
          },
          "execution_count": 107,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = np.argmax(np.sum(pp, axis=0)/3, axis=1)\n",
        "indices1 = np.where(x == 1)[0]\n",
        "indices0 = np.where(x == 0)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Prediction with Soft Voting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/maurizio/miniconda3/lib/python3.10/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
            "  return bound(*args, **kwds)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'E': 0, 'NE': 1}\n",
            "label\n",
            "NE       1600\n",
            "E        1242\n",
            "Name: count, dtype: int64\n",
            "Classification with LGBM...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "5-fold: 100%|██████████| 5/5 [00:14<00:00,  2.98s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'E': 0, 'NE': 1}\n",
            "label\n",
            "NE       1600\n",
            "E        1242\n",
            "Name: count, dtype: int64\n",
            "Classification with LGBM...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "5-fold: 100%|██████████| 5/5 [00:16<00:00,  3.21s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'E': 0, 'NE': 1}\n",
            "label\n",
            "NE       1600\n",
            "E        1242\n",
            "Name: count, dtype: int64\n",
            "Classification with LGBM...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "5-fold: 100%|██████████| 5/5 [00:15<00:00,  3.12s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'E': 0, 'NE': 1}\n",
            "label\n",
            "NE       1600\n",
            "E        1242\n",
            "Name: count, dtype: int64\n",
            "Classification with LGBM...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "5-fold: 100%|██████████| 5/5 [00:15<00:00,  3.18s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'E': 0, 'NE': 1}\n",
            "label\n",
            "NE       1599\n",
            "E        1242\n",
            "Name: count, dtype: int64\n",
            "Classification with LGBM...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "5-fold: 100%|██████████| 5/5 [00:14<00:00,  2.91s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'E': 0, 'NE': 1}\n",
            "label\n",
            "NE       1599\n",
            "E        1242\n",
            "Name: count, dtype: int64\n",
            "Classification with LGBM...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "5-fold: 100%|██████████| 5/5 [00:14<00:00,  2.96s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'E': 0, 'NE': 1}\n",
            "label\n",
            "NE       1599\n",
            "E        1242\n",
            "Name: count, dtype: int64\n",
            "Classification with LGBM...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "5-fold: 100%|██████████| 5/5 [00:15<00:00,  3.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'E': 0, 'NE': 1}\n",
            "label\n",
            "NE       1599\n",
            "E        1242\n",
            "Name: count, dtype: int64\n",
            "Classification with LGBM...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "5-fold: 100%|██████████| 5/5 [00:15<00:00,  3.03s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'E': 0, 'NE': 1}\n",
            "label\n",
            "NE       1599\n",
            "E        1242\n",
            "Name: count, dtype: int64\n",
            "Classification with LGBM...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "5-fold: 100%|██████████| 5/5 [00:13<00:00,  2.74s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'E': 0, 'NE': 1}\n",
            "label\n",
            "NE       1599\n",
            "E        1242\n",
            "Name: count, dtype: int64\n",
            "Classification with LGBM...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "5-fold: 100%|██████████| 5/5 [00:13<00:00,  2.63s/it]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from help.models.prediction import predict_cv\n",
        "seed=42\n",
        "df_y_ne = df_y[df_y['label']=='NE']\n",
        "df_y_e = df_y[df_y['label']=='E']\n",
        "#df_y_ne = df_y_ne.sample(frac=1, random_state=seed)\n",
        "n_voters = 7\n",
        "splits = np.array_split(df_y_ne, n_voters) \n",
        "predictions_ne = pd.DataFrame()\n",
        "predictions_e = pd.DataFrame(index=df_y_e.index)\n",
        "d=np.empty((len(df_y_e.index),),object)\n",
        "d[...]=[list() for _ in range(len(df_y_e.index))]\n",
        "predictions_e['probabilities'] = d\n",
        "predictions_e['label'] = np.array([0 for idx in df_y_e.index])\n",
        "predictions_e['prediction'] = np.array([np.nan for idx in df_y_e.index])\n",
        "for df_index_ne in splits:\n",
        "    df_x = pd.concat([df_X.loc[df_index_ne.index], df_X.loc[df_y_e.index]])\n",
        "    df_yy = pd.concat([df_y.loc[df_index_ne.index], df_y_e])\n",
        "    _, _, preds = predict_cv(df_x, df_yy, n_splits=5, method='LGBM', balanced=True, verbose=True, seed=seed)\n",
        "    predictions_ne = pd.concat([predictions_ne, preds.loc[df_index_ne.index]])\n",
        "    r = np.empty((len(df_y_e.index),),object)\n",
        "    r[...]=[predictions_e.loc[idx]['probabilities'] + [preds.loc[idx]['probabilities']]  for idx in df_y_e.index]\n",
        "    predictions_e['probabilities'] = r\n",
        "predictions_e['prediction'] = predictions_e['probabilities'].map(lambda x: 0 if sum(x)/n_voters > 0.5 else 1)\n",
        "predictions_e['probabilities'] = predictions_e['probabilities'].map(lambda x: sum(x)/n_voters)\n",
        "predictions = pd.concat([predictions_ne, predictions_e])\n",
        "predictions.to_csv(f\"pred_Kidney_SV_{n_voters}.csv\", index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions_e.to_csv(\"pred_Kidney_SV.csv\", index=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 4375833,
          "sourceId": 7595933,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30646,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
