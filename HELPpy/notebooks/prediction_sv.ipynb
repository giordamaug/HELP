{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lavaILXgTTl0"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/giordamaug/HELP/blob/main/help/notebooks/prediction.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n",
        "<a target=\"_blank\" href=\"https://www.kaggle.com/notebooks/welcome?src=https://github.com/giordamaug/HELP/blob/main/help/notebooks/prediction.ipynb\">\n",
        "  <img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joeFb6T-TTl3"
      },
      "source": [
        "# Install HELP from GitHub\n",
        "Skip this cell if you already have installed HELP."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tuF0S73STTl4",
        "outputId": "e6d33ca9-a106-46fe-df06-3f8c3075441f"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/giordamaug/HELP.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFrBvM5ErPN4"
      },
      "source": [
        "# Download the input files\n",
        "In this cell we download from GitHub repository the label file and the attribute files. Skip this step if you already have these input files locally."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wbcOjf7TTl5",
        "outputId": "350746d3-7293-4f67-cc3a-7295acbfa022"
      },
      "outputs": [],
      "source": [
        "tissue='Kidney'\n",
        "!wget https://raw.githubusercontent.com/giordamaug/HELP/main/help/datafinal/{tissue}_HELP.csv\n",
        "!wget https://raw.githubusercontent.com/giordamaug/HELP/main/help/datafinal/{tissue}_BIO.csv\n",
        "for i in range(5):\n",
        "  !wget https://raw.githubusercontent.com/giordamaug/HELP/main/help/datafinal/{tissue}_CCcfs_{i}.csv\n",
        "!wget https://raw.githubusercontent.com/giordamaug/HELP/main/help/datafinal/{tissue}_EmbN2V_128.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/maurizio/HELP/data\n"
          ]
        }
      ],
      "source": [
        "%cd ../../data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqSGGzfNTTl6"
      },
      "source": [
        "# Process the tissue attributes\n",
        "In this code we load tissue gene attributes by several datafiles. We apply missing values fixing and data scaling with `sklearn.preprocessing.StandardScaler` on the `BIO` and `CCcfs` attributes, while no normalization and fixing on embedding attributes (`EmbN2V_128`). The attributes are all merged in one matrix by the `feature_assemble` function as input for the prediction model building."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        },
        "execution": {
          "iopub.execute_input": "2024-02-13T11:09:02.545717Z",
          "iopub.status.busy": "2024-02-13T11:09:02.545238Z",
          "iopub.status.idle": "2024-02-13T11:09:16.557744Z",
          "shell.execute_reply": "2024-02-13T11:09:16.556982Z",
          "shell.execute_reply.started": "2024-02-13T11:09:02.545678Z"
        },
        "id": "toAayH83TTl7",
        "outputId": "25f23ce9-ac16-4ecc-95ee-8153c74656d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label\n",
            "NE       16678\n",
            "E         1253\n",
            "Name: count, dtype: int64\n",
            "Majority NE 16678 minority E 1253\n",
            "[Kidney_BIO.csv] found 52532 Nan...\n",
            "[Kidney_BIO.csv] Normalization with std ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading file in chunks: 100%|██████████| 5/5 [00:02<00:00,  1.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Kidney_CCcfs.csv] found 6676644 Nan...\n",
            "[Kidney_CCcfs.csv] Normalization with std ...\n",
            "[Kidney_EmbN2V_128.csv] found 0 Nan...\n",
            "[Kidney_EmbN2V_128.csv] No normalization...\n",
            "17236 labeled genes over a total of 17931\n",
            "(17236, 3456) data input\n"
          ]
        }
      ],
      "source": [
        "tissue='Kidney'\n",
        "import pandas as pd\n",
        "from HELPpy.preprocess.loaders import feature_assemble_df\n",
        "import os\n",
        "df_y = pd.read_csv(f\"{tissue}_HELP.csv\", index_col=0)\n",
        "df_y = df_y.replace({'aE': 'NE', 'sNE': 'NE'})\n",
        "print(df_y.value_counts(normalize=False))\n",
        "features = [{'fname': f'{tissue}_BIO.csv', 'fixna' : False, 'normalize': 'std'},\n",
        "            {'fname': f'{tissue}_CCcfs.csv', 'fixna' : False, 'normalize': 'std', 'nchunks' : 5},\n",
        "            {'fname': f'{tissue}_EmbN2V_128.csv', 'fixna' : False, 'normalize': None}]\n",
        "df_X, df_y = feature_assemble_df(df_y, features=features, saveflag=False, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import *\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from collections import Counter\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from tqdm import tqdm\n",
        "from tabulate import tabulate\n",
        "from typing import List,Dict,Union,Tuple\n",
        "def set_seed(seed=1):\n",
        "    \"\"\"\n",
        "    Set random and numpy random seed for reproducibility\n",
        "\n",
        "    :param int seed: inistalization seed\n",
        "\n",
        "    :returns None.\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "def predict_cv_(X, Y, n_splits=10, method='LGBM', method_args = {}, balanced=False, saveflag: bool = False, outfile: str = 'predictions.csv', verbose: bool = False, display: bool = False,  seed: int = 42):\n",
        "    \"\"\"\n",
        "    Perform cross-validated predictions using a LightGBM classifier.\n",
        "\n",
        "    :param DataFrame X: Features DataFrame.\n",
        "    :param DataFrame Y: Target variable DataFrame.\n",
        "    :param int n_splits: Number of folds for cross-validation.\n",
        "    :param str method: Classifier method (default LGBM)\n",
        "    :param bool balanced: Whether to use class weights to balance the classes.\n",
        "    :param bool saveflag: Whether to save the predictions to a CSV file.\n",
        "    :param str or None outfile: File name for saving predictions.\n",
        "    :param bool verbose: Whether to print verbose information.\n",
        "    :param bool display: Whether to display a confusion matrix plot.\n",
        "    :param int or None seed: Random seed for reproducibility.\n",
        "\n",
        "    :returns: Summary statistics of the cross-validated predictions, single measures and label predictions\n",
        "    :rtype: Tuple(pd.DataFrame,pd.DataFrame,pd.DataFrame)\n",
        "\n",
        "    :example:\n",
        " \n",
        "    .. code-block:: python\n",
        "\n",
        "        # Example usage\n",
        "        X_data = pd.DataFrame(...)\n",
        "        Y_data = pd.DataFrame(...)\n",
        "        result, _, _ = predict_cv(X_data, Y_data, n_splits=5, balanced=True, saveflag=False, outfile=None, verbose=True, display=True, seed=42)\n",
        "    \"\"\"\n",
        "    methods = {'LGBM': LGBMClassifier, 'SV': VotingSplitClassifier}\n",
        "\n",
        "    # silent twdm if no verbosity\n",
        "    #if not verbose: \n",
        "    #    def notqdm(iterable, *args, **kwargs): return iterable\n",
        "    #    tqdm = notqdm\n",
        "    # get the list of genes\n",
        "    genes = Y.index\n",
        "\n",
        "    # Encode target variable labels\n",
        "    encoder = LabelEncoder()\n",
        "    X = X.values\n",
        "    y = encoder.fit_transform(Y.values.ravel())\n",
        "\n",
        "    # Display class information\n",
        "    classes_mapping = dict(zip(encoder.classes_, encoder.transform(encoder.classes_)))\n",
        "    if verbose: print(f'{classes_mapping}\\n{Y.value_counts()}')\n",
        "\n",
        "    # Set random seed\n",
        "    set_seed(seed)\n",
        "\n",
        "    # Initialize StratifiedKFold\n",
        "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
        "\n",
        "    # Initialize classifier\n",
        "    #clf = LGBMClassifier(class_weight='balanced', verbose=-1) if balanced else LGBMClassifier(verbose=-1)\n",
        "    clf = methods[method](**method_args)\n",
        "\n",
        "    nclasses = len(np.unique(y))\n",
        "    mm = np.array([], dtype=np.int64)\n",
        "    gg = np.array([])\n",
        "    yy = np.array([], dtype=np.int64)\n",
        "    predictions = np.array([], dtype=np.int64)\n",
        "    probabilities = np.array([])\n",
        "\n",
        "    # Columns for result summary\n",
        "    columns_names = [\"ROC-AUC\", \"Accuracy\", \"BA\", \"Sensitivity\", \"Specificity\", \"MCC\", 'CM']\n",
        "    scores = pd.DataFrame()\n",
        "\n",
        "    if verbose:\n",
        "        print(f'Classification with {method}({method_args})...')\n",
        "\n",
        "    # Iterate over each fold\n",
        "    for fold, (train_idx, test_idx) in enumerate(tqdm(kf.split(np.arange(len(X)), y), total=kf.get_n_splits(), desc=f\"{n_splits}-fold\", disable=not verbose)):\n",
        "        train_x, train_y, test_x, test_y = X[train_idx], y[train_idx], X[test_idx], y[test_idx],\n",
        "        mm = np.concatenate((mm, test_idx))\n",
        "        probs = clf.fit(train_x, train_y).predict_proba(test_x)\n",
        "        preds = np.argmax(probs, axis=1)\n",
        "        gg = np.concatenate((gg, genes[test_idx]))\n",
        "        yy = np.concatenate((yy, test_y))\n",
        "        cm = confusion_matrix(test_y, preds)\n",
        "        predictions = np.concatenate((predictions, preds))\n",
        "        probabilities = np.concatenate((probabilities, probs[:, 0]))\n",
        "\n",
        "        # Calculate and store evaluation metrics for each fold\n",
        "        roc_auc = roc_auc_score(test_y, probs[:, 1]) if nclasses == 2 else roc_auc_score(test_y, probs, multi_class=\"ovr\", average=\"macro\")\n",
        "        scores = pd.concat([scores, pd.DataFrame([[roc_auc,\n",
        "                                                    accuracy_score(test_y, preds),\n",
        "                                                    balanced_accuracy_score(test_y, preds),\n",
        "                                                    cm[0, 0] / (cm[0, 0] + cm[0, 1]),\n",
        "                                                    cm[1, 1] / (cm[1, 0] + cm[1, 1]),\n",
        "                                                    matthews_corrcoef(test_y, preds),\n",
        "                                                    cm]],\n",
        "                                                  columns=columns_names, index=[fold])],\n",
        "                           axis=0)\n",
        "\n",
        "    # Calculate mean and standard deviation of evaluation metrics\n",
        "    df_scores = pd.DataFrame([f'{val:.4f}±{err:.4f}' for val, err in zip(scores.loc[:, scores.columns != \"CM\"].mean(axis=0).values,\n",
        "                                                                     scores.loc[:, scores.columns != \"CM\"].std(axis=0))] +\n",
        "                             [(scores[['CM']].sum()).values[0].tolist()],\n",
        "                             columns=['measure'], index=scores.columns)\n",
        "\n",
        "    # Display confusion matrix if requested\n",
        "    if display:\n",
        "        ConfusionMatrixDisplay(confusion_matrix=np.array(df_scores.loc['CM']['measure']), display_labels=encoder.inverse_transform(clf.classes_)).plot()\n",
        "\n",
        "    # Create DataFrame for storing detailed predictions\n",
        "    df_results = pd.DataFrame({'gene': gg, 'label': yy, 'prediction': predictions, 'probabilities': probabilities})\n",
        "    df_results = df_results.set_index(['gene'])\n",
        "\n",
        "    # Save detailed predictions to a CSV file if requested\n",
        "    if saveflag:\n",
        "        df_results.to_csv(outfile)\n",
        "\n",
        "    # Return the summary statistics of cross-validated predictions, the single measures and the prediction results\n",
        "    return df_scores, scores, df_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 1, 1, ..., 1, 1, 1])"
            ]
          },
          "execution_count": 159,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'E': 0, 'NE': 1}\n",
            "label\n",
            "NE       15994\n",
            "E         1242\n",
            "Name: count, dtype: int64\n",
            "Classification with SV({'n_jobs': 1, 'class_weight': 'balanced', 'n_voters': 10, 'verbose': True})...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "5-fold:   0%|          | 0/5 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Majority 1 12795, minority 0 993\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "10-voter: 100%|██████████| 10/10 [00:30<00:00,  3.09s/it]\n",
            "5-fold:  20%|██        | 1/5 [00:31<02:04, 31.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Majority 1 12795, minority 0 994\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "10-voter: 100%|██████████| 10/10 [00:30<00:00,  3.08s/it]\n",
            "5-fold:  40%|████      | 2/5 [01:02<01:33, 31.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Majority 1 12795, minority 0 994\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "10-voter: 100%|██████████| 10/10 [00:30<00:00,  3.02s/it]\n",
            "5-fold:  60%|██████    | 3/5 [01:32<01:01, 30.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Majority 1 12795, minority 0 994\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "10-voter: 100%|██████████| 10/10 [00:30<00:00,  3.01s/it]\n",
            "5-fold:  80%|████████  | 4/5 [02:02<00:30, 30.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Majority 1 12796, minority 0 993\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "10-voter: 100%|██████████| 10/10 [00:31<00:00,  3.12s/it]\n",
            "5-fold: 100%|██████████| 5/5 [02:34<00:00, 30.88s/it]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(                                  measure\n",
              " ROC-AUC                     0.9569±0.0049\n",
              " Accuracy                    0.8767±0.0038\n",
              " BA                          0.8890±0.0076\n",
              " Sensitivity                 0.9034±0.0127\n",
              " Specificity                 0.8746±0.0034\n",
              " MCC                         0.5220±0.0120\n",
              " CM           [[1122, 120], [2006, 13988]],\n",
              "     ROC-AUC  Accuracy        BA  Sensitivity  Specificity       MCC  \\\n",
              " 0  0.957739  0.873840  0.889420     0.907631     0.871210  0.519149   \n",
              " 1  0.964408  0.883087  0.901675     0.923387     0.879962  0.542884   \n",
              " 2  0.956831  0.876704  0.885217     0.895161     0.875274  0.518009   \n",
              " 3  0.951590  0.875544  0.886452     0.899194     0.873711  0.517726   \n",
              " 4  0.953835  0.874093  0.882150     0.891566     0.872733  0.512279   \n",
              " \n",
              "                          CM  \n",
              " 0  [[226, 23], [412, 2787]]  \n",
              " 1  [[229, 19], [384, 2815]]  \n",
              " 2  [[222, 26], [399, 2800]]  \n",
              " 3  [[223, 25], [404, 2795]]  \n",
              " 4  [[222, 27], [407, 2791]]  ,\n",
              "         label  prediction  probabilities\n",
              " gene                                    \n",
              " A2M         1           1       0.053718\n",
              " A2ML1       1           1       0.001416\n",
              " A4GNT       1           1       0.001983\n",
              " AAAS        1           0       0.972745\n",
              " AACS        1           1       0.010481\n",
              " ...       ...         ...            ...\n",
              " ZSCAN9      1           1       0.006688\n",
              " ZSWIM6      1           1       0.003877\n",
              " ZUP1        1           1       0.103805\n",
              " ZYG11A      1           1       0.015577\n",
              " ZZEF1       1           1       0.148494\n",
              " \n",
              " [17236 rows x 3 columns])"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predict_cv_(df_X, df_y, n_splits=5, method='SV', method_args = {'n_jobs' : 1, 'class_weight':'balanced', 'n_voters':10, 'verbose': True}, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.base import clone, BaseEstimator, ClassifierMixin, RegressorMixin\n",
        "from joblib import Parallel, delayed\n",
        "from lightgbm import LGBMClassifier \n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "\n",
        "class VotingSplitClassifier(BaseEstimator, ClassifierMixin):\n",
        "\n",
        "    def __init__(self, n_voters=10, voting='soft', n_jobs=-1, verbose=False, **kwargs):\n",
        "        self.kwargs = kwargs\n",
        "        # intialize ensemble ov voters\n",
        "        self.verbose = verbose\n",
        "        self.n_jobs = n_jobs\n",
        "        self.n_voters = n_voters\n",
        "        self.estimators_ = [LGBMClassifier(**kwargs) for i in range(n_voters)]\n",
        "        pass\n",
        "    \n",
        "    \n",
        "    def _fit_single_estimator(self, i, X, y, index_ne, index_e):\n",
        "        \"\"\"Private function used to fit an estimator within a job.\"\"\"\n",
        "        df_X = np.append(X[index_ne], X[index_e], axis=0)\n",
        "        df_y = np.append(y[index_ne], y[index_e], axis=0)\n",
        "        clf = clone(self.estimators_[i])\n",
        "        clf.fit(df_X, df_y)\n",
        "        return clf\n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        # Find the majority and minority class\n",
        "        assert isinstance(X, np.ndarray) and isinstance(y, np.ndarray), \"Only array input!\"\n",
        "        unique, counts = np.unique(y, return_counts=True)\n",
        "        minlab = unique[np.argmin(counts)]\n",
        "        maxlab = unique[np.argmax(counts)]\n",
        "\n",
        "        if self.verbose:\n",
        "            print(f\"Majority {maxlab} {max(counts)}, minority {minlab} {min(counts)}\")\n",
        "\n",
        "        # Separate majority and minority class\n",
        "        all_index_ne = np.where(y == maxlab)[0]\n",
        "        index_e = np.where(y == minlab)[0]\n",
        "\n",
        "        # Split majority class among voters\n",
        "        splits = np.array_split(all_index_ne, self.n_voters)\n",
        "\n",
        "        self.estimators_ = Parallel(n_jobs=self.n_jobs)(delayed(self._fit_single_estimator)(i,X, y, index_ne, index_e) for i,index_ne in enumerate(tqdm(splits, desc=f\"{self.n_voters}-voter\", disable = not self.verbose)))\n",
        "        #for i,index_ne in enumerate(tqdm(splits, desc=f\"{self.n_voters}-voter\", disable = not self.verbose)):\n",
        "        #    df_X = np.append(X[index_ne], X[index_e], axis=0)\n",
        "        #    df_y = np.append(y[index_ne], y[index_e], axis=0)\n",
        "        #    self.estimators_[i].fit(df_X,df_y)\n",
        "        return self\n",
        "    \n",
        "    def predict_proba(self, X, y=None):\n",
        "        # Find the majority and minority class\n",
        "        assert isinstance(X, np.ndarray), \"Only array input!\"\n",
        "        probabilities = np.array([self.estimators_[i].predict_proba(X) for i in range(self.n_voters)])\n",
        "        return np.sum(probabilities, axis=0)/self.n_voters\n",
        "    \n",
        "    def predict(self, X, y=None):\n",
        "        assert isinstance(X, np.ndarray), \"Only array input!\"\n",
        "        probabilities = np.array([self.estimators_[i].predict_proba(X) for i in range(self.n_voters)])\n",
        "        return np.argmax(np.sum(probabilities, axis=0)/self.n_voters, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['NE', 'NE', 'NE', ..., 'NE', 'NE', 'NE'], dtype=object)"
            ]
          },
          "execution_count": 183,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_y.values.ravel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 194,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Majority NE 1242, minority E 15994\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "3-voter:   0%|          | 0/3 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "3-voter: 100%|██████████| 3/3 [01:02<00:00, 20.90s/it]\n"
          ]
        }
      ],
      "source": [
        "clf = VotingSplitClassifier(n_voters=3, class_weight='balanced', verbose=True)\n",
        "pp = clf.fit(df_X.values, df_y.values.ravel()).predict_proba(df_X.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(17236, 2)"
            ]
          },
          "execution_count": 196,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pp.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {},
      "outputs": [],
      "source": [
        "pp = clf.predict_proba(df_X.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([    7,    14,    16, ..., 17225, 17226, 17227])"
            ]
          },
          "execution_count": 107,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = np.argmax(np.sum(pp, axis=0)/3, axis=1)\n",
        "indices1 = np.where(x == 1)[0]\n",
        "indices0 = np.where(x == 0)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Prediction with Soft Voting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/maurizio/miniconda3/lib/python3.10/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
            "  return bound(*args, **kwds)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'E': 0, 'NE': 1}\n",
            "label\n",
            "NE       1600\n",
            "E        1242\n",
            "Name: count, dtype: int64\n",
            "Classification with LGBM...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "5-fold: 100%|██████████| 5/5 [00:14<00:00,  2.98s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'E': 0, 'NE': 1}\n",
            "label\n",
            "NE       1600\n",
            "E        1242\n",
            "Name: count, dtype: int64\n",
            "Classification with LGBM...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "5-fold: 100%|██████████| 5/5 [00:16<00:00,  3.21s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'E': 0, 'NE': 1}\n",
            "label\n",
            "NE       1600\n",
            "E        1242\n",
            "Name: count, dtype: int64\n",
            "Classification with LGBM...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "5-fold: 100%|██████████| 5/5 [00:15<00:00,  3.12s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'E': 0, 'NE': 1}\n",
            "label\n",
            "NE       1600\n",
            "E        1242\n",
            "Name: count, dtype: int64\n",
            "Classification with LGBM...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "5-fold: 100%|██████████| 5/5 [00:15<00:00,  3.18s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'E': 0, 'NE': 1}\n",
            "label\n",
            "NE       1599\n",
            "E        1242\n",
            "Name: count, dtype: int64\n",
            "Classification with LGBM...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "5-fold: 100%|██████████| 5/5 [00:14<00:00,  2.91s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'E': 0, 'NE': 1}\n",
            "label\n",
            "NE       1599\n",
            "E        1242\n",
            "Name: count, dtype: int64\n",
            "Classification with LGBM...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "5-fold: 100%|██████████| 5/5 [00:14<00:00,  2.96s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'E': 0, 'NE': 1}\n",
            "label\n",
            "NE       1599\n",
            "E        1242\n",
            "Name: count, dtype: int64\n",
            "Classification with LGBM...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "5-fold: 100%|██████████| 5/5 [00:15<00:00,  3.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'E': 0, 'NE': 1}\n",
            "label\n",
            "NE       1599\n",
            "E        1242\n",
            "Name: count, dtype: int64\n",
            "Classification with LGBM...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "5-fold: 100%|██████████| 5/5 [00:15<00:00,  3.03s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'E': 0, 'NE': 1}\n",
            "label\n",
            "NE       1599\n",
            "E        1242\n",
            "Name: count, dtype: int64\n",
            "Classification with LGBM...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "5-fold: 100%|██████████| 5/5 [00:13<00:00,  2.74s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'E': 0, 'NE': 1}\n",
            "label\n",
            "NE       1599\n",
            "E        1242\n",
            "Name: count, dtype: int64\n",
            "Classification with LGBM...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "5-fold: 100%|██████████| 5/5 [00:13<00:00,  2.63s/it]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from help.models.prediction import predict_cv\n",
        "seed=42\n",
        "df_y_ne = df_y[df_y['label']=='NE']\n",
        "df_y_e = df_y[df_y['label']=='E']\n",
        "#df_y_ne = df_y_ne.sample(frac=1, random_state=seed)\n",
        "n_voters = 7\n",
        "splits = np.array_split(df_y_ne, n_voters) \n",
        "predictions_ne = pd.DataFrame()\n",
        "predictions_e = pd.DataFrame(index=df_y_e.index)\n",
        "d=np.empty((len(df_y_e.index),),object)\n",
        "d[...]=[list() for _ in range(len(df_y_e.index))]\n",
        "predictions_e['probabilities'] = d\n",
        "predictions_e['label'] = np.array([0 for idx in df_y_e.index])\n",
        "predictions_e['prediction'] = np.array([np.nan for idx in df_y_e.index])\n",
        "for df_index_ne in splits:\n",
        "    df_x = pd.concat([df_X.loc[df_index_ne.index], df_X.loc[df_y_e.index]])\n",
        "    df_yy = pd.concat([df_y.loc[df_index_ne.index], df_y_e])\n",
        "    _, _, preds = predict_cv(df_x, df_yy, n_splits=5, method='LGBM', balanced=True, verbose=True, seed=seed)\n",
        "    predictions_ne = pd.concat([predictions_ne, preds.loc[df_index_ne.index]])\n",
        "    r = np.empty((len(df_y_e.index),),object)\n",
        "    r[...]=[predictions_e.loc[idx]['probabilities'] + [preds.loc[idx]['probabilities']]  for idx in df_y_e.index]\n",
        "    predictions_e['probabilities'] = r\n",
        "predictions_e['prediction'] = predictions_e['probabilities'].map(lambda x: 0 if sum(x)/n_voters > 0.5 else 1)\n",
        "predictions_e['probabilities'] = predictions_e['probabilities'].map(lambda x: sum(x)/n_voters)\n",
        "predictions = pd.concat([predictions_ne, predictions_e])\n",
        "predictions.to_csv(f\"pred_Kidney_SV_{n_voters}.csv\", index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions_e.to_csv(\"pred_Kidney_SV.csv\", index=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 4375833,
          "sourceId": 7595933,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30646,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
