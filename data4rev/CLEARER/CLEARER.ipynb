{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Hs Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import *\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Gene Essential CEG  Essential OEG\n",
      "0  ENSG00000107581     Essential      Essential\n",
      "1  ENSG00000068654     Essential            NaN\n",
      "2  ENSG00000088325     Essential            NaN\n",
      "4  ENSG00000165732     Essential  Non-essential\n",
      "5  ENSG00000085840     Essential  Non-essential\n",
      "Essential CEG\n",
      "Non-essential    13743\n",
      "Essential          833\n",
      "Name: count, dtype: int64\n",
      "Essential CEG\n",
      "1    13743\n",
      "0      833\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Set working directory\n",
    "#os.chdir(\"/to/CLEARER_directory/\")\n",
    "EsInfo = pd.read_csv(\"Class_labels/Hs.csv\", sep=\",\", header=0)\n",
    "EsInfo = EsInfo[EsInfo['Essential CEG'].notna()] # remove rows with NaN in 'Essential CEG'\n",
    "print(EsInfo.head())\n",
    "print(EsInfo['Essential CEG'].value_counts())\n",
    "\n",
    "# Generate class labels suitable for Python\n",
    "EsInfo['Essential CEG'] = EsInfo['Essential CEG'].astype('category').cat.codes\n",
    "EsInfo.set_index('Gene', inplace=True)\n",
    "print(EsInfo['Essential CEG'].value_counts())\n",
    "\n",
    "# Load combined features\n",
    "Data = pd.read_csv(\"Features/Hs_features.csv.gz\", sep=\",\", header=0, compression='gzip')\n",
    "Data.set_index('genes', inplace=True)\n",
    "\n",
    "# reduce to sahred index\n",
    "idxcommon = np.intersect1d(EsInfo.index.values, Data.index.values)\n",
    "Data = Data.loc[idxcommon]\n",
    "EsInfo = EsInfo.loc[idxcommon]\n",
    "\n",
    "# Assign class labels\n",
    "Data['label'] = EsInfo['Essential CEG']\n",
    "\n",
    "# Randomize Data\n",
    "np.random.seed(69)\n",
    "Data = Data.sample(frac=1).reset_index()\n",
    "Data = Data.set_index('genes')\n",
    "\n",
    "X = Data.iloc[:, :-1]\n",
    "Y = Data.iloc[:, -1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Bio+CCcfs+embed features\n",
    "Load the ENS to symbol convertion dictionary for genes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = \"../../data\"\n",
    "def get_ens_dict(file_path):\n",
    "    with open(file_path) as f:\n",
    "        gtf = list(f)\n",
    "\n",
    "    gtf = [x for x in gtf if not x.startswith('#')]\n",
    "    gtf = [x for x in gtf if 'gene_id \"' in x and 'gene_name \"' in x]\n",
    "    if len(gtf) == 0:\n",
    "        print('you need to change gene_id \" and gene_name \" formats')\n",
    "    \n",
    "    gtf = list(map(lambda x: (x.split('gene_id \"')[1].split('\"')[0], x.split('gene_name \"')[1].split('\"')[0]), gtf))\n",
    "    gtf = dict(set(gtf))\n",
    "    return gtf\n",
    "\n",
    "gtf_dict = get_ens_dict(os.path.join(path,'Homo_sapiens.GRCh38.112.gtf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Essential CEG\n",
      "Non-essential    13734\n",
      "Essential          833\n",
      "Name: count, dtype: int64\n",
      "                   Gene Essential CEG  Essential OEG\n",
      "gene                                                \n",
      "EIF3A   ENSG00000107581     Essential      Essential\n",
      "POLR1A  ENSG00000068654     Essential            NaN\n",
      "TPX2    ENSG00000088325     Essential            NaN\n",
      "DDX21   ENSG00000165732     Essential  Non-essential\n",
      "ORC1    ENSG00000085840     Essential  Non-essential\n",
      "Essential CEG\n",
      "1    13734\n",
      "0      833\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from HELPpy.preprocess.loaders import load_features\n",
    "path = \"../../data\"\n",
    "Data = load_features([os.path.join(path, \"Human_Bio.csv\"),\n",
    "                      os.path.join(path, \"Human_CCcfs.csv\"),\n",
    "                      os.path.join(path, \"Human_EmbN2V_128.csv\")], fixnans=[True, True, False], normalizes=['std', 'std', None])\n",
    "EsInfo = pd.read_csv(\"Class_labels/Hs.csv\", sep=\",\", header=0)\n",
    "EsInfo['gene'] = EsInfo.apply(lambda x: gtf_dict[x.Gene] if x.Gene in gtf_dict.keys() else np.nan, axis=1)\n",
    "EsInfo = EsInfo[EsInfo['gene'].notna()]\n",
    "EsInfo = EsInfo[EsInfo['Essential CEG'].notna()] # remove rows with NaN in 'Essential CEG'\n",
    "EsInfo.set_index('gene', inplace=True)\n",
    "print(EsInfo['Essential CEG'].value_counts())\n",
    "print(EsInfo.head())\n",
    "\n",
    "# Generate class labels suitable for Python\n",
    "EsInfo['Essential CEG'] = EsInfo['Essential CEG'].astype('category').cat.codes\n",
    "print(EsInfo['Essential CEG'].value_counts())\n",
    "\n",
    "idxcommon = np.intersect1d(EsInfo.index.values, Data.index.values)\n",
    "Data = Data.loc[idxcommon]\n",
    "EsInfo = EsInfo.loc[idxcommon]\n",
    "\n",
    "# Assign class labels\n",
    "Data['label'] = EsInfo['Essential CEG']\n",
    "\n",
    "# Randomize Data\n",
    "np.random.seed(69)\n",
    "Data = Data.sample(frac=1).reset_index()\n",
    "Data = Data.set_index('Gene')\n",
    "\n",
    "X = Data.iloc[:, :-1]\n",
    "Y = Data.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply to Hs Feature set or Bio+CCcfs+embed features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14576, 41635) (14576,)\n",
      "{0: 0, 1: 1}\n",
      "label\n",
      "1    13743\n",
      "0      833\n",
      "Name: count, dtype: int64\n",
      "Classification with RandomForestClassifier...with SMOTE resampling\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7ae8478b6004b1fa71d61fbb20b0e13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "5-fold:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>measure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ROC-AUC</th>\n",
       "      <td>0.9624±0.0035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.9595±0.0029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BA</th>\n",
       "      <td>0.7682±0.0104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sensitivity</th>\n",
       "      <td>0.5522±0.0196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Specificity</th>\n",
       "      <td>0.9841±0.0023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCC</th>\n",
       "      <td>0.5915±0.0260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CM</th>\n",
       "      <td>[[460, 373], [218, 13525]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                measure\n",
       "ROC-AUC                   0.9624±0.0035\n",
       "Accuracy                  0.9595±0.0029\n",
       "BA                        0.7682±0.0104\n",
       "Sensitivity               0.5522±0.0196\n",
       "Specificity               0.9841±0.0023\n",
       "MCC                       0.5915±0.0260\n",
       "CM           [[460, 373], [218, 13525]]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X.shape, Y.shape)\n",
    "from HELPpy.models.prediction import VotingEnsembleLGBM, k_fold_cv\n",
    "#clf = VotingEnsembleLGBM(n_voters=10, learning_rate=0.5, boosting_type='gbdt', n_jobs=-1, random_state=42)\n",
    "clf = RandomForestClassifier(n_estimators=500, n_jobs=-1)\n",
    "df_scores, scores, predictions = k_fold_cv(X, Y, clf, n_splits=5, resample=True, seed=0, show_progress=True, verbose=True)\n",
    "df_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maurizio/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/maurizio/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Feature selection\n",
    "X_train = X\n",
    "y_train = Y\n",
    "\n",
    "# Lasso feature selection using LogisticRegressionCV\n",
    "clf = LogisticRegressionCV(cv=5, penalty='l1', solver='saga', scoring='roc_auc', max_iter=1000).fit(X_train, y_train)\n",
    "model = SelectFromModel(clf, prefit=True)\n",
    "X_train_selected = model.transform(X_train)\n",
    "\n",
    "# Remove highly correlated features\n",
    "corr_matrix = pd.DataFrame(X_train_selected).corr().abs()\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.7)]\n",
    "X_train_selected = pd.DataFrame(X_train_selected).drop(to_drop, axis=1)\n",
    "\n",
    "train_sets[i] = pd.concat([X_train_selected, y_train.reset_index(drop=True)], axis=1)\n",
    "val_sets[i] = val_sets[i][train_sets[i].columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine learning\n",
    "def train_rf(train_data):\n",
    "    X = train_data.iloc[:, :-1]\n",
    "    y = train_data.iloc[:, -1]\n",
    "    \n",
    "    smote = SMOTE()\n",
    "    X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "    \n",
    "    rf = RandomForestClassifier(n_estimators=500, n_jobs=-1)\n",
    "    kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=7)\n",
    "    scores = cross_val_score(rf, X_resampled, y_resampled, cv=kf, scoring='roc_auc')\n",
    "    rf.fit(X_resampled, y_resampled)\n",
    "    return rf, scores.mean()\n",
    "\n",
    "results = Parallel(n_jobs=N)(delayed(train_rf)(train_sets[i]) for i in range(N))\n",
    "rf_list, auc_scores = zip(*results)\n",
    "\n",
    "# Performance evaluation on test set\n",
    "def evaluate_model(rf, val_data):\n",
    "    X_val = val_data.iloc[:, :-1]\n",
    "    y_val = val_data.iloc[:, -1]\n",
    "    \n",
    "    y_pred = rf.predict(X_val)\n",
    "    y_prob = rf.predict_proba(X_val)[:, 1]\n",
    "    \n",
    "    cm = confusion_matrix(y_val, y_pred)\n",
    "    roc_auc = roc_auc_score(y_val, y_prob)\n",
    "    precision, recall, _ = precision_recall_curve(y_val, y_prob)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    \n",
    "    return cm, roc_auc, pr_auc\n",
    "\n",
    "eval_results = [evaluate_model(rf_list[i], val_sets[i]) for i in range(N)]\n",
    "cm_list, roc_auc_list, pr_auc_list = zip(*eval_results)\n",
    "\n",
    "metrics = pd.DataFrame({\n",
    "    'roc_auc': roc_auc_list,\n",
    "    'pr_auc': pr_auc_list\n",
    "})\n",
    "\n",
    "metrics.loc['mean'] = metrics.mean()\n",
    "metrics.loc['std'] = metrics.std()\n",
    "\n",
    "metrics.to_csv(\"test_rf.csv\", index=True)\n",
    "\n",
    "# Performance evaluation on training set\n",
    "def get_best_kappa(rf):\n",
    "    results = pd.DataFrame(rf.cv_results_)\n",
    "    return results.loc[results['mean_test_score'].idxmax()]\n",
    "\n",
    "train_metrics = pd.concat([get_best_kappa(rf_list[i]) for i in range(5)])\n",
    "train_metrics.to_csv(\"train_rf.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pygeometric",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
