{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Gene Essential CEG  Essential OEG\n",
      "0  ENSG00000107581     Essential      Essential\n",
      "1  ENSG00000068654     Essential            NaN\n",
      "2  ENSG00000088325     Essential            NaN\n",
      "3  ENSG00000148835           NaN      Essential\n",
      "4  ENSG00000165732     Essential  Non-essential\n",
      "Essential CEG\n",
      "Non-essential    13743\n",
      "Essential          833\n",
      "Name: count, dtype: int64\n",
      "Essential CEG\n",
      "1.0    13743\n",
      "0.0      833\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, precision_recall_curve, auc\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "import gzip\n",
    "from HELPpy.utility.utils import pandas_readcsv\n",
    "\n",
    "# Set working directory\n",
    "#os.chdir(\"/to/CLEARER_directory/\")\n",
    "EsInfo = pd.read_csv(\"Class_labels/Hs.csv\", sep=\",\", header=0)\n",
    "print(EsInfo.head())\n",
    "print(EsInfo['Essential CEG'].value_counts())\n",
    "\n",
    "# Generate class labels suitable for Python\n",
    "EsInfo['Essential CEG'] = EsInfo['Essential CEG'].dropna().astype('category').cat.codes\n",
    "print(EsInfo['Essential CEG'].value_counts())\n",
    "\n",
    "# Load combined features\n",
    "Data = pd.read_csv(\"Features/Hs_features.csv.gz\", sep=\",\", header=0, compression='gzip')\n",
    "Data.set_index('genes', inplace=True)\n",
    "\n",
    "# Assign class labels\n",
    "Data['label'] = EsInfo.set_index('Gene').loc[Data.index, 'Essential CEG']\n",
    "\n",
    "# Randomize Data\n",
    "np.random.seed(69)\n",
    "Data = Data.sample(frac=1).reset_index()\n",
    "\n",
    "# Split Data\n",
    "N = 5\n",
    "seq = np.round(np.linspace(0, len(Data), N+1)).astype(int)\n",
    "val_sets = [Data.iloc[seq[i]:seq[i+1]].set_index('genes') for i in range(N)]\n",
    "train_sets = [Data.set_index('genes').drop(val.index) for val in val_sets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{-1: 0, 0: 1, 1: 2}\n",
      "label\n",
      " 1    11043\n",
      "-1     4230\n",
      " 0      658\n",
      "Name: count, dtype: int64\n",
      "Classification with VotingEnsembleLGBM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74c567e3665e45cc9c3fa23a26506d41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "5-fold:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Number of classes in y_true not equal to the number of columns in 'y_score'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mHELPpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprediction\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VotingEnsembleLGBM, k_fold_cv\n\u001b[1;32m      4\u001b[0m clf \u001b[38;5;241m=\u001b[39m VotingEnsembleLGBM(n_voters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, boosting_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgbdt\u001b[39m\u001b[38;5;124m'\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m df_scores, scores, predictions \u001b[38;5;241m=\u001b[39m \u001b[43mk_fold_cv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m df_scores\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/HELPpy/models/prediction.py:384\u001b[0m, in \u001b[0;36mk_fold_cv\u001b[0;34m(X, Y, estimator, n_splits, saveflag, outfile, verbose, show_progress, display, seed)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# Iterate over each fold\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fold, (train_idx, test_idx) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(kf\u001b[38;5;241m.\u001b[39msplit(np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(X)), y), total\u001b[38;5;241m=\u001b[39mkf\u001b[38;5;241m.\u001b[39mget_n_splits(), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_splits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-fold\u001b[39m\u001b[38;5;124m\"\u001b[39m, disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m show_progress)):\n\u001b[0;32m--> 384\u001b[0m     genes, targets, predictions, probabilities, metrics \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_fold\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtest_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtest_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m                                                                        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallgenes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtest_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m                                                                        \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprobabilities\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnclasses\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    387\u001b[0m     scores \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([scores, pd\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39mfrom_dict(metrics, orient\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m)], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    389\u001b[0m \u001b[38;5;66;03m# Calculate mean and standard deviation of evaluation metrics\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/HELPpy/models/prediction.py:260\u001b[0m, in \u001b[0;36mevaluate_fold\u001b[0;34m(train_x, train_y, test_x, test_y, estimator, genes, test_genes, targets, predictions, probabilities, fold, nclasses)\u001b[0m\n\u001b[1;32m    257\u001b[0m probabilities \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate((probabilities, probs[:, \u001b[38;5;241m0\u001b[39m]))\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# Calculate and store evaluation metrics for each fold\u001b[39;00m\n\u001b[0;32m--> 260\u001b[0m roc_auc \u001b[38;5;241m=\u001b[39m roc_auc_score(test_y, probs[:, \u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m nclasses \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mroc_auc_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43movr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmacro\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    261\u001b[0m metrics \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: fold,\n\u001b[1;32m    262\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mROC-AUC\u001b[39m\u001b[38;5;124m\"\u001b[39m : roc_auc, \n\u001b[1;32m    263\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m : accuracy_score(test_y, preds),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    267\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMCC\u001b[39m\u001b[38;5;124m\"\u001b[39m : matthews_corrcoef(test_y, preds), \n\u001b[1;32m    268\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCM\u001b[39m\u001b[38;5;124m'\u001b[39m : cm}\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m genes, targets, predictions, probabilities, metrics\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:634\u001b[0m, in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m multi_class \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulti_class must be in (\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124movo\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124movr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 634\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_multiclass_roc_auc_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    638\u001b[0m     labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y_true)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:751\u001b[0m, in \u001b[0;36m_multiclass_roc_auc_score\u001b[0;34m(y_true, y_score, labels, multi_class, average, sample_weight)\u001b[0m\n\u001b[1;32m    749\u001b[0m     classes \u001b[38;5;241m=\u001b[39m _unique(y_true)\n\u001b[1;32m    750\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(classes) \u001b[38;5;241m!=\u001b[39m y_score\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m--> 751\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    752\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of classes in y_true not equal to the number of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    753\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns in \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_score\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    754\u001b[0m         )\n\u001b[1;32m    756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m multi_class \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124movo\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    757\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Number of classes in y_true not equal to the number of columns in 'y_score'"
     ]
    }
   ],
   "source": [
    "X_train = train_sets[0].iloc[:, :-1]\n",
    "y_train = train_sets[0].iloc[:, -1]\n",
    "from HELPpy.models.prediction import VotingEnsembleLGBM, k_fold_cv\n",
    "clf = VotingEnsembleLGBM(n_voters=10, learning_rate=0.5, boosting_type='gbdt', n_jobs=-1, random_state=42)\n",
    "df_scores, scores, predictions = k_fold_cv(X_train, y_train, clf, n_splits=5, seed=0, show_progress=True, verbose=True)\n",
    "df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genes</th>\n",
       "      <th>T3s</th>\n",
       "      <th>C3s</th>\n",
       "      <th>A3s</th>\n",
       "      <th>G3s</th>\n",
       "      <th>CAI.x</th>\n",
       "      <th>CBI</th>\n",
       "      <th>Fop</th>\n",
       "      <th>Nc</th>\n",
       "      <th>GC3s</th>\n",
       "      <th>...</th>\n",
       "      <th>Pc2.Hydrophilicity.26</th>\n",
       "      <th>Pc2.Hydrophobicity.27</th>\n",
       "      <th>Pc2.Hydrophilicity.27</th>\n",
       "      <th>Pc2.Hydrophobicity.28</th>\n",
       "      <th>Pc2.Hydrophilicity.28</th>\n",
       "      <th>Pc2.Hydrophobicity.29</th>\n",
       "      <th>Pc2.Hydrophilicity.29</th>\n",
       "      <th>Pc2.Hydrophobicity.30</th>\n",
       "      <th>Pc2.Hydrophilicity.30</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENSG00000197976</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENSG00000006756</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENSG00000137310</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENSG00000230430</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENSG00000162614</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19909</th>\n",
       "      <td>ENSG00000169752</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19910</th>\n",
       "      <td>ENSG00000197674</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19911</th>\n",
       "      <td>ENSG00000235588</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19912</th>\n",
       "      <td>ENSG00000129932</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19913</th>\n",
       "      <td>ENSG00000196498</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19914 rows × 41637 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 genes  T3s  C3s  A3s  G3s  CAI.x  CBI  Fop  Nc  GC3s  ...  \\\n",
       "0      ENSG00000197976    1    8    1   10      1    9    9  10    10  ...   \n",
       "1      ENSG00000006756    4    7    5    6      3    5    5  10     6  ...   \n",
       "2      ENSG00000137310    3    7    5    7      2    7    8   9     7  ...   \n",
       "3      ENSG00000230430    2   10    3    9     10   10   10   6     9  ...   \n",
       "4      ENSG00000162614    7    3   10    3      7    3    4   4     3  ...   \n",
       "...                ...  ...  ...  ...  ...    ...  ...  ...  ..   ...  ...   \n",
       "19909  ENSG00000169752    9    2   10    2      5    2    2   2     2  ...   \n",
       "19910  ENSG00000197674    7    4   10    1     10    5    5   2     3  ...   \n",
       "19911  ENSG00000235588    3    9    5    4      1    3    2   3     7  ...   \n",
       "19912  ENSG00000129932    2    9    2    9      2    9    9  10     9  ...   \n",
       "19913  ENSG00000196498    2    9    1   10      2    9    8   7     9  ...   \n",
       "\n",
       "       Pc2.Hydrophilicity.26  Pc2.Hydrophobicity.27  Pc2.Hydrophilicity.27  \\\n",
       "0                          2                      2                      2   \n",
       "1                          7                      7                      7   \n",
       "2                          7                      7                      7   \n",
       "3                          5                      5                      5   \n",
       "4                         10                     10                     10   \n",
       "...                      ...                    ...                    ...   \n",
       "19909                      2                      9                      2   \n",
       "19910                      6                      6                      6   \n",
       "19911                      7                      7                      7   \n",
       "19912                      2                      9                      9   \n",
       "19913                     10                      2                     10   \n",
       "\n",
       "       Pc2.Hydrophobicity.28  Pc2.Hydrophilicity.28  Pc2.Hydrophobicity.29  \\\n",
       "0                          2                      2                      2   \n",
       "1                          7                      7                      7   \n",
       "2                          7                      7                      7   \n",
       "3                          5                      5                      5   \n",
       "4                          9                     10                     10   \n",
       "...                      ...                    ...                    ...   \n",
       "19909                      2                      2                      2   \n",
       "19910                      6                      6                      6   \n",
       "19911                      7                      7                      7   \n",
       "19912                      2                      2                     10   \n",
       "19913                     10                     10                     10   \n",
       "\n",
       "       Pc2.Hydrophilicity.29  Pc2.Hydrophobicity.30  Pc2.Hydrophilicity.30  \\\n",
       "0                          2                      2                      2   \n",
       "1                          7                      7                      7   \n",
       "2                          7                      7                      7   \n",
       "3                          5                      5                      5   \n",
       "4                         10                     10                     10   \n",
       "...                      ...                    ...                    ...   \n",
       "19909                      1                      2                      1   \n",
       "19910                      6                      6                      6   \n",
       "19911                      7                      7                      7   \n",
       "19912                     10                      1                      1   \n",
       "19913                      9                     10                     10   \n",
       "\n",
       "       label  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "3         -1  \n",
       "4          1  \n",
       "...      ...  \n",
       "19909      1  \n",
       "19910     -1  \n",
       "19911     -1  \n",
       "19912      0  \n",
       "19913     -1  \n",
       "\n",
       "[19914 rows x 41637 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature selection step:   0%|          | 0/5 [00:00<?, ?it/s]/Users/maurizio/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/maurizio/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/maurizio/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/maurizio/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/maurizio/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/maurizio/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/maurizio/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/maurizio/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/maurizio/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/maurizio/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/maurizio/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/maurizio/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/maurizio/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/maurizio/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/maurizio/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/maurizio/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Feature selection\n",
    "for i in tqdm(range(N), desc=\"Feature selection step\", total=N):\n",
    "    train_set = train_sets[i]\n",
    "    X_train = train_set.iloc[:, :-1]\n",
    "    y_train = train_set.iloc[:, -1]\n",
    "\n",
    "    # Lasso feature selection using LogisticRegressionCV\n",
    "    clf = LogisticRegressionCV(cv=5, penalty='l1', solver='saga', scoring='roc_auc', max_iter=1000).fit(X_train, y_train)\n",
    "    model = SelectFromModel(clf, prefit=True)\n",
    "    X_train_selected = model.transform(X_train)\n",
    "\n",
    "    # Remove highly correlated features\n",
    "    corr_matrix = pd.DataFrame(X_train_selected).corr().abs()\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > 0.7)]\n",
    "    X_train_selected = pd.DataFrame(X_train_selected).drop(to_drop, axis=1)\n",
    "\n",
    "    train_sets[i] = pd.concat([X_train_selected, y_train.reset_index(drop=True)], axis=1)\n",
    "    val_sets[i] = val_sets[i][train_sets[i].columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine learning\n",
    "def train_rf(train_data):\n",
    "    X = train_data.iloc[:, :-1]\n",
    "    y = train_data.iloc[:, -1]\n",
    "    \n",
    "    smote = SMOTE()\n",
    "    X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "    \n",
    "    rf = RandomForestClassifier(n_estimators=500, n_jobs=-1)\n",
    "    kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=7)\n",
    "    scores = cross_val_score(rf, X_resampled, y_resampled, cv=kf, scoring='roc_auc')\n",
    "    rf.fit(X_resampled, y_resampled)\n",
    "    return rf, scores.mean()\n",
    "\n",
    "results = Parallel(n_jobs=N)(delayed(train_rf)(train_sets[i]) for i in range(N))\n",
    "rf_list, auc_scores = zip(*results)\n",
    "\n",
    "# Performance evaluation on test set\n",
    "def evaluate_model(rf, val_data):\n",
    "    X_val = val_data.iloc[:, :-1]\n",
    "    y_val = val_data.iloc[:, -1]\n",
    "    \n",
    "    y_pred = rf.predict(X_val)\n",
    "    y_prob = rf.predict_proba(X_val)[:, 1]\n",
    "    \n",
    "    cm = confusion_matrix(y_val, y_pred)\n",
    "    roc_auc = roc_auc_score(y_val, y_prob)\n",
    "    precision, recall, _ = precision_recall_curve(y_val, y_prob)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    \n",
    "    return cm, roc_auc, pr_auc\n",
    "\n",
    "eval_results = [evaluate_model(rf_list[i], val_sets[i]) for i in range(N)]\n",
    "cm_list, roc_auc_list, pr_auc_list = zip(*eval_results)\n",
    "\n",
    "metrics = pd.DataFrame({\n",
    "    'roc_auc': roc_auc_list,\n",
    "    'pr_auc': pr_auc_list\n",
    "})\n",
    "\n",
    "metrics.loc['mean'] = metrics.mean()\n",
    "metrics.loc['std'] = metrics.std()\n",
    "\n",
    "metrics.to_csv(\"test_rf.csv\", index=True)\n",
    "\n",
    "# Performance evaluation on training set\n",
    "def get_best_kappa(rf):\n",
    "    results = pd.DataFrame(rf.cv_results_)\n",
    "    return results.loc[results['mean_test_score'].idxmax()]\n",
    "\n",
    "train_metrics = pd.concat([get_best_kappa(rf_list[i]) for i in range(5)])\n",
    "train_metrics.to_csv(\"train_rf.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pygeometric",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
