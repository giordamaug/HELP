{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'optuna'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/5l/8d8z3krn5zv78v2zfzk06p0m0000gn/T/ipykernel_6848/929804267.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'optuna'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pprint import pprint\n",
    "sys.path.append('.')\n",
    "\n",
    "from utils import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import optuna\n",
    "from sklearn import metrics\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import *\n",
    "from gat import *\n",
    "\n",
    "modelname = 'GAT'\n",
    "\n",
    "def get_snapshot_name(name, expr_path, ortho_path, subloc_path, no_ppi, weights):\n",
    "    snapshot_name = f'{name}'\n",
    "    snapshot_name += f'_expr' if expr_path is not None else ''\n",
    "    snapshot_name += f'_ortho' if ortho_path is not None else ''\n",
    "    snapshot_name += f'_subl' if subloc_path is not None else ''\n",
    "    snapshot_name += f'_ppi' if not no_ppi else ''\n",
    "    snapshot_name += f'_w' if weights else ''\n",
    "    return snapshot_name\n",
    "\n",
    "def main(name, label_path, ppi_path=None,\n",
    "         expr_path=None, ortho_path=None, subloc_path=None, no_ppi=False, \n",
    "         weights=False, seed=0, train_mode=False, n_epochs=1000, \n",
    "         savedir='.', predsavedir='.', verbose=False):\n",
    "\n",
    "    set_seed(seed)\n",
    "\n",
    "    snapshot_name = get_snapshot_name(name, expr_path, ortho_path, subloc_path, no_ppi, weights)\n",
    "\n",
    "    savepath = os.path.join(savedir, snapshot_name)\n",
    "\n",
    "    # Getting the data ----------------------------------\n",
    "    (edge_index, edge_weights), X, (train_idx, train_y), \\\n",
    "        (val_idx, val_y), (test_idx, test_y), genes = data(label_path, ppi_path, expr_path, ortho_path, subloc_path, no_ppi=no_ppi, weights=weights, verbose=verbose)\n",
    "    if verbose: print('Fetched data')\n",
    "\n",
    "    # Train the model -----------------------------------\n",
    "    if train_mode:\n",
    "        if verbose: print('\\nTraining the model')\n",
    "        gat_params = gat_human\n",
    "        model = train(gat_params, X, edge_index, edge_weights,\n",
    "                        train_y, train_idx, val_y, val_idx, n_epochs=n_epochs, savepath=savepath)\n",
    "    # ---------------------------------------------------\n",
    "\n",
    "    # Load trained model --------------------------------\n",
    "    if verbose: print(f'\\nLoading the model from: {savepath}')\n",
    "    snapshot = torch.load(savepath)\n",
    "    model = GAT(in_feats=X.shape[1], **snapshot['model_params'])\n",
    "    model.load_state_dict(snapshot['model_state_dict'])\n",
    "    if verbose: print('Model loaded. Val AUC: {}'.format(snapshot['auc']))\n",
    "    # ---------------------------------------------------\n",
    "\n",
    "    # Test the model ------------------------------------\n",
    "    preds, auc, score, ba, mcc, sens, specs = test(model, X, edge_index, (test_idx, test_y))\n",
    "    preds = np.concatenate(\n",
    "        [genes[test_idx].reshape((-1, 1)), preds[test_idx]], axis=1)\n",
    "    save_preds(modelname, preds, predsavedir, snapshot_name, seed=seed)\n",
    "    if verbose: \n",
    "        print('Test AUC:', auc)\n",
    "        print('Test Accuracy:', score)\n",
    "        print('Test BA:', ba)\n",
    "        print('Test Sens.', sens)\n",
    "        print('Test Sp.', specs)\n",
    "        print('Test MCC:', mcc)\n",
    "    # ---------------------------------------------------\n",
    "\n",
    "    return preds, auc, score, ba, mcc, sens, specs\n",
    "\n",
    "path = \"../../data\"\n",
    "ipath = \"./data\"\n",
    "n_runs = None\n",
    "n_epochs = 1000\n",
    "seed=0\n",
    "name ='kidney'\n",
    "label_path = os.path.join(path, 'Kidney_HELP_2.csv')\n",
    "ppi_path = os.path.join(path, 'Kidney_PPI.csv')\n",
    "expr_path=None #os.path.join(ipath, 'GTEX_expr_kidney.csv'),\n",
    "ortho_path=None #os.path.join(ipath, 'Orthologs_kidney.csv'),\n",
    "subloc_path=os.path.join(ipath, 'Sublocs_kidney.csv') \n",
    "no_ppi=False \n",
    "weights=False\n",
    "train_mode = True\n",
    "hypersearch = True\n",
    "snapshot_name = get_snapshot_name(name, expr_path, ortho_path, subloc_path, no_ppi, weights)\n",
    "\n",
    "if hypersearch:\n",
    "    seed = np.random.randint(1000) + 10\n",
    "    datasets = []\n",
    "    for i in range(3):\n",
    "        set_seed(seed+i)\n",
    "        datasets += [data(label_path, ppi_path, expr_path, ortho_path, subloc_path, no_ppi=no_ppi, weights=weights, verbose=True) for i in range(3)]\n",
    "    hyper_search(name, './studies', datasets)\n",
    "elif n_runs:\n",
    "    print(f'Training on {n_runs} runs')\n",
    "    m = np.array([main(name, label_path, \n",
    "        ppi_path=ppi_path, expr_path=expr_path, ortho_path=ortho_path, subloc_path=subloc_path, \n",
    "        no_ppi=no_ppi, weights=weights, train_mode=train_mode, n_epochs=n_epochs,\n",
    "        savedir='models', predsavedir='results',seed=i)[1:] for i in range(n_runs)])\n",
    "    measures = np.ravel(np.column_stack((np.mean(m, axis=0),np.std(m, axis=0))))\n",
    "    save_results(os.path.join('results', f'{modelname}_{snapshot_name}_r{n_runs}.csv'), *measures)\n",
    "else:\n",
    "    print('Training a single run with seed', seed)\n",
    "    main(name, label_path, \n",
    "        ppi_path=ppi_path, expr_path=expr_path, ortho_path=ortho_path, subloc_path=subloc_path, \n",
    "        no_ppi=no_ppi, weights=weights, train_mode=train_mode, n_epochs=n_epochs,\n",
    "        savedir='models', predsavedir='results',seed=seed, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
