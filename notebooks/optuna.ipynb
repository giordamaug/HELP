{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github.com/giordamaug/HELP/blob/v2.0/notebooks/optuna.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "<a target=\"_blank\" href=\"https://www.kaggle.com/notebooks/welcome?src=https://github.com/giordamaug/HELP/blob/v2.0/notebooks/optuna.ipynb\">\n",
    "  <img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load optuna library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, sys \n",
    "import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Download the input files\n",
    "For a chosen tissue (here `Kidney`), download from Zenodo [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.12597679.svg)](https://doi.org/10.5281/zenodo.12597679)\n",
    " the label file (here `Kidney_HELP.csv`, computed as in Example 1) and the attribute files (here BIO `Kidney_BIO.csv`, CCcfs `Kidney_CCcfs.csv`, and N2V `Kidney_EmbN2V_128.csv`).  \n",
    "\n",
    "Skip this step if you already have these input files locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HELPpy.utility.utils import pdread_csv_fromurl\n",
    "tissue='Kidney'\n",
    "X_bio = pdread_csv_fromurl(f\"https://zenodo.org/records/11917458/files/{tissue}_BIO.csv\", index_col=0)\n",
    "X_n2v = pdread_csv_fromurl(f\"https://zenodo.org/records/11917458/files/{tissue}_EmbN2V_128.csv\", index_col=0)\n",
    "X_cccfs = pdread_csv_fromurl(f\"https://zenodo.org/records/11917458/files/{tissue}_CCcfs.csv\", index_col=0)\n",
    "Y = pdread_csv_fromurl(f\"https://zenodo.org/records/11917458/files/{tissue}_HELP.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Pre-processing and merge input files\n",
    "We apply pre-processing only to the BIO and CCcfs attributes.\n",
    "+ constant attributes removal, and\n",
    "+ data scaling with z-score.  \n",
    "\n",
    "We also replace `E` label (positive label) and `aE` and `sNE` labels as 0 label (negative label), to address binary `E vs NE` classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0        16678\n",
      "1         1253\n",
      "Name: count, dtype: int64\n",
      "Removing 0 constant features ...\n",
      "Removing 3 constant features ...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "df_y = Y.replace({'aE': 0, 'sNE': 0, 'E': 1})\n",
    "print(df_y.value_counts(normalize=False))\n",
    "consts = X_bio.columns[X_bio.nunique() <= 1].values\n",
    "print(f\"Removing {len(consts)} constant features ...\")\n",
    "X_bio = X_bio.drop(consts, axis=1)\n",
    "X_bio = pd.DataFrame(StandardScaler().fit_transform(X_bio), index=X_bio.index, columns=X_bio.columns)\n",
    "X_cccfs = pd.DataFrame(StandardScaler().fit_transform(X_cccfs), index=X_cccfs.index, columns=X_cccfs.columns)\n",
    "consts = X_cccfs.columns[X_cccfs.nunique() <= 1].values\n",
    "print(f\"Removing {len(consts)} constant features ...\")\n",
    "X_cccfs = X_cccfs.drop(consts, axis=1)\n",
    "df_X = pd.merge(X_bio, X_n2v, left_index=True, right_index=True, how='outer')\n",
    "df_X = pd.merge(df_X, X_cccfs, left_index=True, right_index=True, how='outer')\n",
    "idxs = np.intersect1d(df_y.index.values, df_X.index.values)\n",
    "df_X = df_X.loc[idxs]\n",
    "df_y = df_y.loc[idxs]\n",
    "dataset = pd.concat([df_X,df_y], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Tune model (Optuna)\n",
    "Start tuning session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 10:55:43,546] A new study created in RDB with name: svelgbm_Kidney\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(learning_rate=0.0248461687421351, n_estimators=120, verbose=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 10:56:47,274] Trial 0 finished with value: 0.8423182798142357 and parameters: {'learning_rate': 0.0248461687421351, 'n_voters': 4, 'n_estimators': 120}. Best is trial 0 with value: 0.8423182798142357.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(learning_rate=0.04595068893557344, verbose=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 10:58:07,822] Trial 1 finished with value: 0.8825998371421111 and parameters: {'learning_rate': 0.04595068893557344, 'n_voters': 11, 'n_estimators': 100}. Best is trial 1 with value: 0.8825998371421111.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(learning_rate=0.0016002303899586149, n_estimators=120,\n",
      "               verbose=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 10:59:42,360] Trial 2 finished with value: 0.8244511361248665 and parameters: {'learning_rate': 0.0016002303899586149, 'n_voters': 15, 'n_estimators': 120}. Best is trial 1 with value: 0.8825998371421111.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(learning_rate=0.0021560531082856806, n_estimators=200,\n",
      "               verbose=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 11:02:34,379] Trial 3 finished with value: 0.8087380880638652 and parameters: {'learning_rate': 0.0021560531082856806, 'n_voters': 19, 'n_estimators': 200}. Best is trial 1 with value: 0.8825998371421111.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(learning_rate=0.01061710292709643, n_estimators=200, verbose=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 11:05:31,056] Trial 4 finished with value: 0.862527755664263 and parameters: {'learning_rate': 0.01061710292709643, 'n_voters': 18, 'n_estimators': 200}. Best is trial 1 with value: 0.8825998371421111.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(learning_rate=0.011826757340963001, n_estimators=60, verbose=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 11:06:25,194] Trial 5 finished with value: 0.8525893009258467 and parameters: {'learning_rate': 0.011826757340963001, 'n_voters': 15, 'n_estimators': 60}. Best is trial 1 with value: 0.8825998371421111.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(learning_rate=0.0032038374530860836, n_estimators=140,\n",
      "               verbose=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 11:07:33,717] Trial 6 finished with value: 0.6828651919662436 and parameters: {'learning_rate': 0.0032038374530860836, 'n_voters': 6, 'n_estimators': 140}. Best is trial 1 with value: 0.8825998371421111.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(learning_rate=0.00802883321752304, n_estimators=80, verbose=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 11:08:45,854] Trial 7 finished with value: 0.8546726544503075 and parameters: {'learning_rate': 0.00802883321752304, 'n_voters': 13, 'n_estimators': 80}. Best is trial 1 with value: 0.8825998371421111.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(learning_rate=0.002010040901901548, n_estimators=60, verbose=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 11:09:46,146] Trial 8 finished with value: 0.5 and parameters: {'learning_rate': 0.002010040901901548, 'n_voters': 10, 'n_estimators': 60}. Best is trial 1 with value: 0.8825998371421111.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(learning_rate=0.05710066130791045, n_estimators=140, verbose=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 11:11:05,290] Trial 9 finished with value: 0.8870848581954445 and parameters: {'learning_rate': 0.05710066130791045, 'n_voters': 8, 'n_estimators': 140}. Best is trial 9 with value: 0.8870848581954445.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(learning_rate=0.09146556119631263, n_estimators=160, verbose=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 11:12:42,524] Trial 10 finished with value: 0.808477662463827 and parameters: {'learning_rate': 0.09146556119631263, 'n_voters': 2, 'n_estimators': 160}. Best is trial 9 with value: 0.8870848581954445.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(learning_rate=0.0893491248622469, verbose=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 11:13:48,172] Trial 11 finished with value: 0.8881069187519547 and parameters: {'learning_rate': 0.0893491248622469, 'n_voters': 8, 'n_estimators': 100}. Best is trial 11 with value: 0.8881069187519547.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(learning_rate=0.07560145883580464, n_estimators=160, verbose=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 11:15:19,157] Trial 12 finished with value: 0.8882469317660051 and parameters: {'learning_rate': 0.07560145883580464, 'n_voters': 7, 'n_estimators': 160}. Best is trial 12 with value: 0.8882469317660051.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(learning_rate=0.09393495320636834, n_estimators=160, verbose=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 11:16:44,250] Trial 13 finished with value: 0.8892691483211632 and parameters: {'learning_rate': 0.09393495320636834, 'n_voters': 7, 'n_estimators': 160}. Best is trial 13 with value: 0.8892691483211632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(learning_rate=0.03295317406647674, n_estimators=180, verbose=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 11:19:02,916] Trial 14 finished with value: 0.7461932268130556 and parameters: {'learning_rate': 0.03295317406647674, 'n_voters': 1, 'n_estimators': 180}. Best is trial 13 with value: 0.8892691483211632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(learning_rate=0.022076075041580386, n_estimators=160, verbose=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 11:20:19,061] Trial 15 finished with value: 0.8653358371139737 and parameters: {'learning_rate': 0.022076075041580386, 'n_voters': 5, 'n_estimators': 160}. Best is trial 13 with value: 0.8892691483211632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(learning_rate=0.09849119540851549, n_estimators=160, verbose=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 11:21:49,640] Trial 16 finished with value: 0.8917341854054097 and parameters: {'learning_rate': 0.09849119540851549, 'n_voters': 8, 'n_estimators': 160}. Best is trial 16 with value: 0.8917341854054097.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(learning_rate=0.04196453872369558, n_estimators=180, verbose=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 11:24:06,964] Trial 17 finished with value: 0.8872392981928992 and parameters: {'learning_rate': 0.04196453872369558, 'n_voters': 10, 'n_estimators': 180}. Best is trial 16 with value: 0.8917341854054097.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(learning_rate=0.01576264442969468, n_estimators=180, verbose=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 11:25:27,518] Trial 18 finished with value: 0.8430325034762894 and parameters: {'learning_rate': 0.01576264442969468, 'n_voters': 4, 'n_estimators': 180}. Best is trial 16 with value: 0.8917341854054097.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(learning_rate=0.0054431895332090465, n_estimators=140,\n",
      "               verbose=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 11:27:00,098] Trial 19 finished with value: 0.8601254824528546 and parameters: {'learning_rate': 0.0054431895332090465, 'n_voters': 12, 'n_estimators': 140}. Best is trial 16 with value: 0.8917341854054097.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(learning_rate=0.05705304125657472, n_estimators=160, verbose=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 11:28:58,596] Trial 20 finished with value: 0.886633701101931 and parameters: {'learning_rate': 0.05705304125657472, 'n_voters': 9, 'n_estimators': 160}. Best is trial 16 with value: 0.8917341854054097.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(learning_rate=0.0974494790595188, n_estimators=160, verbose=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 11:30:20,389] Trial 21 finished with value: 0.8879094646563501 and parameters: {'learning_rate': 0.0974494790595188, 'n_voters': 7, 'n_estimators': 160}. Best is trial 16 with value: 0.8917341854054097.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(learning_rate=0.06837731574910705, n_estimators=180, verbose=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 11:31:56,895] Trial 22 finished with value: 0.8821528131518155 and parameters: {'learning_rate': 0.06837731574910705, 'n_voters': 6, 'n_estimators': 180}. Best is trial 16 with value: 0.8917341854054097.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(learning_rate=0.03555778457205543, n_estimators=160, verbose=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 11:33:21,391] Trial 23 finished with value: 0.8342191340340298 and parameters: {'learning_rate': 0.03555778457205543, 'n_voters': 3, 'n_estimators': 160}. Best is trial 16 with value: 0.8917341854054097.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(learning_rate=0.0766180503582529, n_estimators=140, verbose=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 11:34:37,217] Trial 24 finished with value: 0.8879673399029413 and parameters: {'learning_rate': 0.0766180503582529, 'n_voters': 7, 'n_estimators': 140}. Best is trial 16 with value: 0.8917341854054097.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(learning_rate=0.001073088062590435, n_estimators=120, verbose=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 11:36:02,290] Trial 25 finished with value: 0.5 and parameters: {'learning_rate': 0.001073088062590435, 'n_voters': 9, 'n_estimators': 120}. Best is trial 16 with value: 0.8917341854054097.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(learning_rate=0.028044249818514427, n_estimators=200, verbose=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 11:38:26,332] Trial 26 finished with value: 0.8860289047912943 and parameters: {'learning_rate': 0.028044249818514427, 'n_voters': 13, 'n_estimators': 200}. Best is trial 16 with value: 0.8917341854054097.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(learning_rate=0.05340341881135604, n_estimators=180, verbose=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 11:39:57,617] Trial 27 finished with value: 0.8766539957767343 and parameters: {'learning_rate': 0.05340341881135604, 'n_voters': 5, 'n_estimators': 180}. Best is trial 16 with value: 0.8917341854054097.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(learning_rate=0.01572482110438377, n_estimators=160, verbose=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 11:41:28,330] Trial 28 finished with value: 0.8702948813092004 and parameters: {'learning_rate': 0.01572482110438377, 'n_voters': 8, 'n_estimators': 160}. Best is trial 16 with value: 0.8917341854054097.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(learning_rate=0.022835172937625794, n_estimators=140, verbose=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 11:42:42,974] Trial 29 finished with value: 0.8503057797795253 and parameters: {'learning_rate': 0.022835172937625794, 'n_voters': 4, 'n_estimators': 140}. Best is trial 16 with value: 0.8917341854054097.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(learning_rate=0.06846946339781423, n_estimators=120, verbose=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 11:43:49,527] Trial 30 finished with value: 0.881066613677201 and parameters: {'learning_rate': 0.06846946339781423, 'n_voters': 6, 'n_estimators': 120}. Best is trial 16 with value: 0.8917341854054097.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(learning_rate=0.09782906480567212, verbose=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 11:44:50,621] Trial 31 finished with value: 0.888138295818076 and parameters: {'learning_rate': 0.09782906480567212, 'n_voters': 8, 'n_estimators': 100}. Best is trial 16 with value: 0.8917341854054097.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(learning_rate=0.099925967041437, verbose=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 11:46:13,205] Trial 32 finished with value: 0.8915232053115947 and parameters: {'learning_rate': 0.099925967041437, 'n_voters': 10, 'n_estimators': 100}. Best is trial 16 with value: 0.8917341854054097.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(learning_rate=0.04274515983020996, n_estimators=80, verbose=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 11:47:19,185] Trial 33 finished with value: 0.876726345263247 and parameters: {'learning_rate': 0.04274515983020996, 'n_voters': 11, 'n_estimators': 80}. Best is trial 16 with value: 0.8917341854054097.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(learning_rate=0.05512800065174187, n_estimators=80, verbose=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 11:48:27,475] Trial 34 finished with value: 0.8848775502091785 and parameters: {'learning_rate': 0.05512800065174187, 'n_voters': 12, 'n_estimators': 80}. Best is trial 16 with value: 0.8917341854054097.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(learning_rate=0.0716980409725318, n_estimators=120, verbose=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 11:50:05,831] Trial 35 finished with value: 0.8877728981313167 and parameters: {'learning_rate': 0.0716980409725318, 'n_voters': 9, 'n_estimators': 120}. Best is trial 16 with value: 0.8917341854054097.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(learning_rate=0.04501210357537029, verbose=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 11:51:25,425] Trial 36 finished with value: 0.8811024123072269 and parameters: {'learning_rate': 0.04501210357537029, 'n_voters': 11, 'n_estimators': 100}. Best is trial 16 with value: 0.8917341854054097.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(learning_rate=0.07391699513802302, n_estimators=140, verbose=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 11:53:23,735] Trial 37 finished with value: 0.8867185934322764 and parameters: {'learning_rate': 0.07391699513802302, 'n_voters': 15, 'n_estimators': 140}. Best is trial 16 with value: 0.8917341854054097.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(learning_rate=0.09835244722478238, n_estimators=200, verbose=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 11:55:08,516] Trial 38 finished with value: 0.8890238016397012 and parameters: {'learning_rate': 0.09835244722478238, 'n_voters': 7, 'n_estimators': 200}. Best is trial 16 with value: 0.8917341854054097.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(learning_rate=0.006429955219775193, n_estimators=200, verbose=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 11:56:38,719] Trial 39 finished with value: 0.8252090774455908 and parameters: {'learning_rate': 0.006429955219775193, 'n_voters': 5, 'n_estimators': 200}. Best is trial 16 with value: 0.8917341854054097.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(learning_rate=0.0042986032380782965, n_estimators=200,\n",
      "               verbose=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 11:59:01,340] Trial 40 finished with value: 0.8482407193253166 and parameters: {'learning_rate': 0.0042986032380782965, 'n_voters': 16, 'n_estimators': 200}. Best is trial 16 with value: 0.8917341854054097.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(learning_rate=0.08009840556773724, n_estimators=180, verbose=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 12:00:36,368] Trial 41 finished with value: 0.8875704653431417 and parameters: {'learning_rate': 0.08009840556773724, 'n_voters': 7, 'n_estimators': 180}. Best is trial 16 with value: 0.8917341854054097.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(learning_rate=0.0635898528194928, n_estimators=160, verbose=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 12:02:39,888] Trial 42 finished with value: 0.889752334987716 and parameters: {'learning_rate': 0.0635898528194928, 'n_voters': 10, 'n_estimators': 160}. Best is trial 16 with value: 0.8917341854054097.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(learning_rate=0.05959270356585158, n_estimators=200, verbose=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 12:05:08,737] Trial 43 finished with value: 0.8908746230488939 and parameters: {'learning_rate': 0.05959270356585158, 'n_voters': 10, 'n_estimators': 200}. Best is trial 16 with value: 0.8917341854054097.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(learning_rate=0.05909917439393716, n_estimators=80, verbose=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 12:06:16,426] Trial 44 finished with value: 0.8839133901150182 and parameters: {'learning_rate': 0.05909917439393716, 'n_voters': 10, 'n_estimators': 80}. Best is trial 16 with value: 0.8917341854054097.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(learning_rate=0.03537637848373053, n_estimators=180, verbose=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 12:08:27,617] Trial 45 finished with value: 0.8862233885170034 and parameters: {'learning_rate': 0.03537637848373053, 'n_voters': 12, 'n_estimators': 180}. Best is trial 16 with value: 0.8917341854054097.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(learning_rate=0.048076337542907986, n_estimators=140, verbose=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 12:10:46,219] Trial 46 finished with value: 0.8771458980914252 and parameters: {'learning_rate': 0.048076337542907986, 'n_voters': 20, 'n_estimators': 140}. Best is trial 16 with value: 0.8917341854054097.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(learning_rate=0.06315578114943135, n_estimators=160, verbose=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 12:12:47,715] Trial 47 finished with value: 0.8890155793590235 and parameters: {'learning_rate': 0.06315578114943135, 'n_voters': 13, 'n_estimators': 160}. Best is trial 16 with value: 0.8917341854054097.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(learning_rate=0.028516454048403726, n_estimators=120, verbose=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 12:14:20,022] Trial 48 finished with value: 0.8762906353732578 and parameters: {'learning_rate': 0.028516454048403726, 'n_voters': 9, 'n_estimators': 120}. Best is trial 16 with value: 0.8917341854054097.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(learning_rate=0.08091938660708022, n_estimators=60, verbose=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 12:15:15,039] Trial 49 finished with value: 0.8835040647930708 and parameters: {'learning_rate': 0.08091938660708022, 'n_voters': 14, 'n_estimators': 60}. Best is trial 16 with value: 0.8917341854054097.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'learning_rate': 0.09849119540851549, 'n_voters': 8, 'n_estimators': 160}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_complete</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_learning_rate</th>\n",
       "      <th>params_n_estimators</th>\n",
       "      <th>params_n_voters</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.891734</td>\n",
       "      <td>2024-07-04 11:20:19.065674</td>\n",
       "      <td>2024-07-04 11:21:49.634990</td>\n",
       "      <td>0 days 00:01:30.569316</td>\n",
       "      <td>0.098491</td>\n",
       "      <td>160</td>\n",
       "      <td>8</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>0.891523</td>\n",
       "      <td>2024-07-04 11:44:50.626033</td>\n",
       "      <td>2024-07-04 11:46:13.200748</td>\n",
       "      <td>0 days 00:01:22.574715</td>\n",
       "      <td>0.099926</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>0.890875</td>\n",
       "      <td>2024-07-04 12:02:39.893239</td>\n",
       "      <td>2024-07-04 12:05:08.732783</td>\n",
       "      <td>0 days 00:02:28.839544</td>\n",
       "      <td>0.059593</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>0.889752</td>\n",
       "      <td>2024-07-04 12:00:36.373211</td>\n",
       "      <td>2024-07-04 12:02:39.883011</td>\n",
       "      <td>0 days 00:02:03.509800</td>\n",
       "      <td>0.063590</td>\n",
       "      <td>160</td>\n",
       "      <td>10</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.889269</td>\n",
       "      <td>2024-07-04 11:15:19.161824</td>\n",
       "      <td>2024-07-04 11:16:44.245516</td>\n",
       "      <td>0 days 00:01:25.083692</td>\n",
       "      <td>0.093935</td>\n",
       "      <td>160</td>\n",
       "      <td>7</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>0.889024</td>\n",
       "      <td>2024-07-04 11:53:23.740206</td>\n",
       "      <td>2024-07-04 11:55:08.511564</td>\n",
       "      <td>0 days 00:01:44.771358</td>\n",
       "      <td>0.098352</td>\n",
       "      <td>200</td>\n",
       "      <td>7</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>0.889016</td>\n",
       "      <td>2024-07-04 12:10:46.224222</td>\n",
       "      <td>2024-07-04 12:12:47.710893</td>\n",
       "      <td>0 days 00:02:01.486671</td>\n",
       "      <td>0.063156</td>\n",
       "      <td>160</td>\n",
       "      <td>13</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.888247</td>\n",
       "      <td>2024-07-04 11:13:48.176688</td>\n",
       "      <td>2024-07-04 11:15:19.152513</td>\n",
       "      <td>0 days 00:01:30.975825</td>\n",
       "      <td>0.075601</td>\n",
       "      <td>160</td>\n",
       "      <td>7</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>0.888138</td>\n",
       "      <td>2024-07-04 11:43:49.532099</td>\n",
       "      <td>2024-07-04 11:44:50.617137</td>\n",
       "      <td>0 days 00:01:01.085038</td>\n",
       "      <td>0.097829</td>\n",
       "      <td>100</td>\n",
       "      <td>8</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.888107</td>\n",
       "      <td>2024-07-04 11:12:42.528982</td>\n",
       "      <td>2024-07-04 11:13:48.167375</td>\n",
       "      <td>0 days 00:01:05.638393</td>\n",
       "      <td>0.089349</td>\n",
       "      <td>100</td>\n",
       "      <td>8</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>0.887967</td>\n",
       "      <td>2024-07-04 11:33:21.395484</td>\n",
       "      <td>2024-07-04 11:34:37.213171</td>\n",
       "      <td>0 days 00:01:15.817687</td>\n",
       "      <td>0.076618</td>\n",
       "      <td>140</td>\n",
       "      <td>7</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0.887909</td>\n",
       "      <td>2024-07-04 11:28:58.600753</td>\n",
       "      <td>2024-07-04 11:30:20.384303</td>\n",
       "      <td>0 days 00:01:21.783550</td>\n",
       "      <td>0.097449</td>\n",
       "      <td>160</td>\n",
       "      <td>7</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>0.887773</td>\n",
       "      <td>2024-07-04 11:48:27.479501</td>\n",
       "      <td>2024-07-04 11:50:05.821012</td>\n",
       "      <td>0 days 00:01:38.341511</td>\n",
       "      <td>0.071698</td>\n",
       "      <td>120</td>\n",
       "      <td>9</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>0.887570</td>\n",
       "      <td>2024-07-04 11:59:01.345293</td>\n",
       "      <td>2024-07-04 12:00:36.364198</td>\n",
       "      <td>0 days 00:01:35.018905</td>\n",
       "      <td>0.080098</td>\n",
       "      <td>180</td>\n",
       "      <td>7</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.887239</td>\n",
       "      <td>2024-07-04 11:21:49.644537</td>\n",
       "      <td>2024-07-04 11:24:06.959602</td>\n",
       "      <td>0 days 00:02:17.315065</td>\n",
       "      <td>0.041965</td>\n",
       "      <td>180</td>\n",
       "      <td>10</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.887085</td>\n",
       "      <td>2024-07-04 11:09:46.150616</td>\n",
       "      <td>2024-07-04 11:11:05.286030</td>\n",
       "      <td>0 days 00:01:19.135414</td>\n",
       "      <td>0.057101</td>\n",
       "      <td>140</td>\n",
       "      <td>8</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>0.886719</td>\n",
       "      <td>2024-07-04 11:51:25.430098</td>\n",
       "      <td>2024-07-04 11:53:23.731041</td>\n",
       "      <td>0 days 00:01:58.300943</td>\n",
       "      <td>0.073917</td>\n",
       "      <td>140</td>\n",
       "      <td>15</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0.886634</td>\n",
       "      <td>2024-07-04 11:27:00.102187</td>\n",
       "      <td>2024-07-04 11:28:58.591646</td>\n",
       "      <td>0 days 00:01:58.489459</td>\n",
       "      <td>0.057053</td>\n",
       "      <td>160</td>\n",
       "      <td>9</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>0.886223</td>\n",
       "      <td>2024-07-04 12:06:16.431199</td>\n",
       "      <td>2024-07-04 12:08:27.612570</td>\n",
       "      <td>0 days 00:02:11.181371</td>\n",
       "      <td>0.035376</td>\n",
       "      <td>180</td>\n",
       "      <td>12</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>0.886029</td>\n",
       "      <td>2024-07-04 11:36:02.295334</td>\n",
       "      <td>2024-07-04 11:38:26.327964</td>\n",
       "      <td>0 days 00:02:24.032630</td>\n",
       "      <td>0.028044</td>\n",
       "      <td>200</td>\n",
       "      <td>13</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>0.884878</td>\n",
       "      <td>2024-07-04 11:47:19.190244</td>\n",
       "      <td>2024-07-04 11:48:27.469940</td>\n",
       "      <td>0 days 00:01:08.279696</td>\n",
       "      <td>0.055128</td>\n",
       "      <td>80</td>\n",
       "      <td>12</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>0.883913</td>\n",
       "      <td>2024-07-04 12:05:08.742403</td>\n",
       "      <td>2024-07-04 12:06:16.422137</td>\n",
       "      <td>0 days 00:01:07.679734</td>\n",
       "      <td>0.059099</td>\n",
       "      <td>80</td>\n",
       "      <td>10</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>0.883504</td>\n",
       "      <td>2024-07-04 12:14:20.027262</td>\n",
       "      <td>2024-07-04 12:15:15.034205</td>\n",
       "      <td>0 days 00:00:55.006943</td>\n",
       "      <td>0.080919</td>\n",
       "      <td>60</td>\n",
       "      <td>14</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.882600</td>\n",
       "      <td>2024-07-04 10:56:47.279181</td>\n",
       "      <td>2024-07-04 10:58:07.817988</td>\n",
       "      <td>0 days 00:01:20.538807</td>\n",
       "      <td>0.045951</td>\n",
       "      <td>100</td>\n",
       "      <td>11</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0.882153</td>\n",
       "      <td>2024-07-04 11:30:20.393325</td>\n",
       "      <td>2024-07-04 11:31:56.891023</td>\n",
       "      <td>0 days 00:01:36.497698</td>\n",
       "      <td>0.068377</td>\n",
       "      <td>180</td>\n",
       "      <td>6</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>0.881102</td>\n",
       "      <td>2024-07-04 11:50:05.835990</td>\n",
       "      <td>2024-07-04 11:51:25.420652</td>\n",
       "      <td>0 days 00:01:19.584662</td>\n",
       "      <td>0.045012</td>\n",
       "      <td>100</td>\n",
       "      <td>11</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>0.881067</td>\n",
       "      <td>2024-07-04 11:42:42.979291</td>\n",
       "      <td>2024-07-04 11:43:49.523109</td>\n",
       "      <td>0 days 00:01:06.543818</td>\n",
       "      <td>0.068469</td>\n",
       "      <td>120</td>\n",
       "      <td>6</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>0.877146</td>\n",
       "      <td>2024-07-04 12:08:27.621484</td>\n",
       "      <td>2024-07-04 12:10:46.215005</td>\n",
       "      <td>0 days 00:02:18.593521</td>\n",
       "      <td>0.048076</td>\n",
       "      <td>140</td>\n",
       "      <td>20</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>0.876726</td>\n",
       "      <td>2024-07-04 11:46:13.209859</td>\n",
       "      <td>2024-07-04 11:47:19.181329</td>\n",
       "      <td>0 days 00:01:05.971470</td>\n",
       "      <td>0.042745</td>\n",
       "      <td>80</td>\n",
       "      <td>11</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>0.876654</td>\n",
       "      <td>2024-07-04 11:38:26.337235</td>\n",
       "      <td>2024-07-04 11:39:57.612740</td>\n",
       "      <td>0 days 00:01:31.275505</td>\n",
       "      <td>0.053403</td>\n",
       "      <td>180</td>\n",
       "      <td>5</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>0.876291</td>\n",
       "      <td>2024-07-04 12:12:47.720209</td>\n",
       "      <td>2024-07-04 12:14:20.018165</td>\n",
       "      <td>0 days 00:01:32.297956</td>\n",
       "      <td>0.028516</td>\n",
       "      <td>120</td>\n",
       "      <td>9</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>0.870295</td>\n",
       "      <td>2024-07-04 11:39:57.621831</td>\n",
       "      <td>2024-07-04 11:41:28.325222</td>\n",
       "      <td>0 days 00:01:30.703391</td>\n",
       "      <td>0.015725</td>\n",
       "      <td>160</td>\n",
       "      <td>8</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.865336</td>\n",
       "      <td>2024-07-04 11:19:02.921970</td>\n",
       "      <td>2024-07-04 11:20:19.056508</td>\n",
       "      <td>0 days 00:01:16.134538</td>\n",
       "      <td>0.022076</td>\n",
       "      <td>160</td>\n",
       "      <td>5</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.862528</td>\n",
       "      <td>2024-07-04 11:02:34.383549</td>\n",
       "      <td>2024-07-04 11:05:31.051711</td>\n",
       "      <td>0 days 00:02:56.668162</td>\n",
       "      <td>0.010617</td>\n",
       "      <td>200</td>\n",
       "      <td>18</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.860125</td>\n",
       "      <td>2024-07-04 11:25:27.522890</td>\n",
       "      <td>2024-07-04 11:27:00.092443</td>\n",
       "      <td>0 days 00:01:32.569553</td>\n",
       "      <td>0.005443</td>\n",
       "      <td>140</td>\n",
       "      <td>12</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.854673</td>\n",
       "      <td>2024-07-04 11:07:33.721892</td>\n",
       "      <td>2024-07-04 11:08:45.849791</td>\n",
       "      <td>0 days 00:01:12.127899</td>\n",
       "      <td>0.008029</td>\n",
       "      <td>80</td>\n",
       "      <td>13</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.852589</td>\n",
       "      <td>2024-07-04 11:05:31.060632</td>\n",
       "      <td>2024-07-04 11:06:25.189780</td>\n",
       "      <td>0 days 00:00:54.129148</td>\n",
       "      <td>0.011827</td>\n",
       "      <td>60</td>\n",
       "      <td>15</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>0.850306</td>\n",
       "      <td>2024-07-04 11:41:28.337396</td>\n",
       "      <td>2024-07-04 11:42:42.969973</td>\n",
       "      <td>0 days 00:01:14.632577</td>\n",
       "      <td>0.022835</td>\n",
       "      <td>140</td>\n",
       "      <td>4</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>0.848241</td>\n",
       "      <td>2024-07-04 11:56:38.725084</td>\n",
       "      <td>2024-07-04 11:59:01.336166</td>\n",
       "      <td>0 days 00:02:22.611082</td>\n",
       "      <td>0.004299</td>\n",
       "      <td>200</td>\n",
       "      <td>16</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.843033</td>\n",
       "      <td>2024-07-04 11:24:06.968805</td>\n",
       "      <td>2024-07-04 11:25:27.513519</td>\n",
       "      <td>0 days 00:01:20.544714</td>\n",
       "      <td>0.015763</td>\n",
       "      <td>180</td>\n",
       "      <td>4</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.842318</td>\n",
       "      <td>2024-07-04 10:55:43.551269</td>\n",
       "      <td>2024-07-04 10:56:47.268530</td>\n",
       "      <td>0 days 00:01:03.717261</td>\n",
       "      <td>0.024846</td>\n",
       "      <td>120</td>\n",
       "      <td>4</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>0.834219</td>\n",
       "      <td>2024-07-04 11:31:56.900268</td>\n",
       "      <td>2024-07-04 11:33:21.386974</td>\n",
       "      <td>0 days 00:01:24.486706</td>\n",
       "      <td>0.035558</td>\n",
       "      <td>160</td>\n",
       "      <td>3</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>0.825209</td>\n",
       "      <td>2024-07-04 11:55:08.520572</td>\n",
       "      <td>2024-07-04 11:56:38.715245</td>\n",
       "      <td>0 days 00:01:30.194673</td>\n",
       "      <td>0.006430</td>\n",
       "      <td>200</td>\n",
       "      <td>5</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.824451</td>\n",
       "      <td>2024-07-04 10:58:07.826815</td>\n",
       "      <td>2024-07-04 10:59:42.355834</td>\n",
       "      <td>0 days 00:01:34.529019</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>120</td>\n",
       "      <td>15</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.808738</td>\n",
       "      <td>2024-07-04 10:59:42.363784</td>\n",
       "      <td>2024-07-04 11:02:34.374124</td>\n",
       "      <td>0 days 00:02:52.010340</td>\n",
       "      <td>0.002156</td>\n",
       "      <td>200</td>\n",
       "      <td>19</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.808478</td>\n",
       "      <td>2024-07-04 11:11:05.295228</td>\n",
       "      <td>2024-07-04 11:12:42.520294</td>\n",
       "      <td>0 days 00:01:37.225066</td>\n",
       "      <td>0.091466</td>\n",
       "      <td>160</td>\n",
       "      <td>2</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.746193</td>\n",
       "      <td>2024-07-04 11:16:44.254775</td>\n",
       "      <td>2024-07-04 11:19:02.911947</td>\n",
       "      <td>0 days 00:02:18.657172</td>\n",
       "      <td>0.032953</td>\n",
       "      <td>180</td>\n",
       "      <td>1</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.682865</td>\n",
       "      <td>2024-07-04 11:06:25.200801</td>\n",
       "      <td>2024-07-04 11:07:33.712447</td>\n",
       "      <td>0 days 00:01:08.511646</td>\n",
       "      <td>0.003204</td>\n",
       "      <td>140</td>\n",
       "      <td>6</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2024-07-04 11:08:45.858518</td>\n",
       "      <td>2024-07-04 11:09:46.141905</td>\n",
       "      <td>0 days 00:01:00.283387</td>\n",
       "      <td>0.002010</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2024-07-04 11:34:37.221977</td>\n",
       "      <td>2024-07-04 11:36:02.286033</td>\n",
       "      <td>0 days 00:01:25.064056</td>\n",
       "      <td>0.001073</td>\n",
       "      <td>120</td>\n",
       "      <td>9</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    number     value             datetime_start          datetime_complete  \\\n",
       "16      16  0.891734 2024-07-04 11:20:19.065674 2024-07-04 11:21:49.634990   \n",
       "32      32  0.891523 2024-07-04 11:44:50.626033 2024-07-04 11:46:13.200748   \n",
       "43      43  0.890875 2024-07-04 12:02:39.893239 2024-07-04 12:05:08.732783   \n",
       "42      42  0.889752 2024-07-04 12:00:36.373211 2024-07-04 12:02:39.883011   \n",
       "13      13  0.889269 2024-07-04 11:15:19.161824 2024-07-04 11:16:44.245516   \n",
       "38      38  0.889024 2024-07-04 11:53:23.740206 2024-07-04 11:55:08.511564   \n",
       "47      47  0.889016 2024-07-04 12:10:46.224222 2024-07-04 12:12:47.710893   \n",
       "12      12  0.888247 2024-07-04 11:13:48.176688 2024-07-04 11:15:19.152513   \n",
       "31      31  0.888138 2024-07-04 11:43:49.532099 2024-07-04 11:44:50.617137   \n",
       "11      11  0.888107 2024-07-04 11:12:42.528982 2024-07-04 11:13:48.167375   \n",
       "24      24  0.887967 2024-07-04 11:33:21.395484 2024-07-04 11:34:37.213171   \n",
       "21      21  0.887909 2024-07-04 11:28:58.600753 2024-07-04 11:30:20.384303   \n",
       "35      35  0.887773 2024-07-04 11:48:27.479501 2024-07-04 11:50:05.821012   \n",
       "41      41  0.887570 2024-07-04 11:59:01.345293 2024-07-04 12:00:36.364198   \n",
       "17      17  0.887239 2024-07-04 11:21:49.644537 2024-07-04 11:24:06.959602   \n",
       "9        9  0.887085 2024-07-04 11:09:46.150616 2024-07-04 11:11:05.286030   \n",
       "37      37  0.886719 2024-07-04 11:51:25.430098 2024-07-04 11:53:23.731041   \n",
       "20      20  0.886634 2024-07-04 11:27:00.102187 2024-07-04 11:28:58.591646   \n",
       "45      45  0.886223 2024-07-04 12:06:16.431199 2024-07-04 12:08:27.612570   \n",
       "26      26  0.886029 2024-07-04 11:36:02.295334 2024-07-04 11:38:26.327964   \n",
       "34      34  0.884878 2024-07-04 11:47:19.190244 2024-07-04 11:48:27.469940   \n",
       "44      44  0.883913 2024-07-04 12:05:08.742403 2024-07-04 12:06:16.422137   \n",
       "49      49  0.883504 2024-07-04 12:14:20.027262 2024-07-04 12:15:15.034205   \n",
       "1        1  0.882600 2024-07-04 10:56:47.279181 2024-07-04 10:58:07.817988   \n",
       "22      22  0.882153 2024-07-04 11:30:20.393325 2024-07-04 11:31:56.891023   \n",
       "36      36  0.881102 2024-07-04 11:50:05.835990 2024-07-04 11:51:25.420652   \n",
       "30      30  0.881067 2024-07-04 11:42:42.979291 2024-07-04 11:43:49.523109   \n",
       "46      46  0.877146 2024-07-04 12:08:27.621484 2024-07-04 12:10:46.215005   \n",
       "33      33  0.876726 2024-07-04 11:46:13.209859 2024-07-04 11:47:19.181329   \n",
       "27      27  0.876654 2024-07-04 11:38:26.337235 2024-07-04 11:39:57.612740   \n",
       "48      48  0.876291 2024-07-04 12:12:47.720209 2024-07-04 12:14:20.018165   \n",
       "28      28  0.870295 2024-07-04 11:39:57.621831 2024-07-04 11:41:28.325222   \n",
       "15      15  0.865336 2024-07-04 11:19:02.921970 2024-07-04 11:20:19.056508   \n",
       "4        4  0.862528 2024-07-04 11:02:34.383549 2024-07-04 11:05:31.051711   \n",
       "19      19  0.860125 2024-07-04 11:25:27.522890 2024-07-04 11:27:00.092443   \n",
       "7        7  0.854673 2024-07-04 11:07:33.721892 2024-07-04 11:08:45.849791   \n",
       "5        5  0.852589 2024-07-04 11:05:31.060632 2024-07-04 11:06:25.189780   \n",
       "29      29  0.850306 2024-07-04 11:41:28.337396 2024-07-04 11:42:42.969973   \n",
       "40      40  0.848241 2024-07-04 11:56:38.725084 2024-07-04 11:59:01.336166   \n",
       "18      18  0.843033 2024-07-04 11:24:06.968805 2024-07-04 11:25:27.513519   \n",
       "0        0  0.842318 2024-07-04 10:55:43.551269 2024-07-04 10:56:47.268530   \n",
       "23      23  0.834219 2024-07-04 11:31:56.900268 2024-07-04 11:33:21.386974   \n",
       "39      39  0.825209 2024-07-04 11:55:08.520572 2024-07-04 11:56:38.715245   \n",
       "2        2  0.824451 2024-07-04 10:58:07.826815 2024-07-04 10:59:42.355834   \n",
       "3        3  0.808738 2024-07-04 10:59:42.363784 2024-07-04 11:02:34.374124   \n",
       "10      10  0.808478 2024-07-04 11:11:05.295228 2024-07-04 11:12:42.520294   \n",
       "14      14  0.746193 2024-07-04 11:16:44.254775 2024-07-04 11:19:02.911947   \n",
       "6        6  0.682865 2024-07-04 11:06:25.200801 2024-07-04 11:07:33.712447   \n",
       "8        8  0.500000 2024-07-04 11:08:45.858518 2024-07-04 11:09:46.141905   \n",
       "25      25  0.500000 2024-07-04 11:34:37.221977 2024-07-04 11:36:02.286033   \n",
       "\n",
       "                 duration  params_learning_rate  params_n_estimators  \\\n",
       "16 0 days 00:01:30.569316              0.098491                  160   \n",
       "32 0 days 00:01:22.574715              0.099926                  100   \n",
       "43 0 days 00:02:28.839544              0.059593                  200   \n",
       "42 0 days 00:02:03.509800              0.063590                  160   \n",
       "13 0 days 00:01:25.083692              0.093935                  160   \n",
       "38 0 days 00:01:44.771358              0.098352                  200   \n",
       "47 0 days 00:02:01.486671              0.063156                  160   \n",
       "12 0 days 00:01:30.975825              0.075601                  160   \n",
       "31 0 days 00:01:01.085038              0.097829                  100   \n",
       "11 0 days 00:01:05.638393              0.089349                  100   \n",
       "24 0 days 00:01:15.817687              0.076618                  140   \n",
       "21 0 days 00:01:21.783550              0.097449                  160   \n",
       "35 0 days 00:01:38.341511              0.071698                  120   \n",
       "41 0 days 00:01:35.018905              0.080098                  180   \n",
       "17 0 days 00:02:17.315065              0.041965                  180   \n",
       "9  0 days 00:01:19.135414              0.057101                  140   \n",
       "37 0 days 00:01:58.300943              0.073917                  140   \n",
       "20 0 days 00:01:58.489459              0.057053                  160   \n",
       "45 0 days 00:02:11.181371              0.035376                  180   \n",
       "26 0 days 00:02:24.032630              0.028044                  200   \n",
       "34 0 days 00:01:08.279696              0.055128                   80   \n",
       "44 0 days 00:01:07.679734              0.059099                   80   \n",
       "49 0 days 00:00:55.006943              0.080919                   60   \n",
       "1  0 days 00:01:20.538807              0.045951                  100   \n",
       "22 0 days 00:01:36.497698              0.068377                  180   \n",
       "36 0 days 00:01:19.584662              0.045012                  100   \n",
       "30 0 days 00:01:06.543818              0.068469                  120   \n",
       "46 0 days 00:02:18.593521              0.048076                  140   \n",
       "33 0 days 00:01:05.971470              0.042745                   80   \n",
       "27 0 days 00:01:31.275505              0.053403                  180   \n",
       "48 0 days 00:01:32.297956              0.028516                  120   \n",
       "28 0 days 00:01:30.703391              0.015725                  160   \n",
       "15 0 days 00:01:16.134538              0.022076                  160   \n",
       "4  0 days 00:02:56.668162              0.010617                  200   \n",
       "19 0 days 00:01:32.569553              0.005443                  140   \n",
       "7  0 days 00:01:12.127899              0.008029                   80   \n",
       "5  0 days 00:00:54.129148              0.011827                   60   \n",
       "29 0 days 00:01:14.632577              0.022835                  140   \n",
       "40 0 days 00:02:22.611082              0.004299                  200   \n",
       "18 0 days 00:01:20.544714              0.015763                  180   \n",
       "0  0 days 00:01:03.717261              0.024846                  120   \n",
       "23 0 days 00:01:24.486706              0.035558                  160   \n",
       "39 0 days 00:01:30.194673              0.006430                  200   \n",
       "2  0 days 00:01:34.529019              0.001600                  120   \n",
       "3  0 days 00:02:52.010340              0.002156                  200   \n",
       "10 0 days 00:01:37.225066              0.091466                  160   \n",
       "14 0 days 00:02:18.657172              0.032953                  180   \n",
       "6  0 days 00:01:08.511646              0.003204                  140   \n",
       "8  0 days 00:01:00.283387              0.002010                   60   \n",
       "25 0 days 00:01:25.064056              0.001073                  120   \n",
       "\n",
       "    params_n_voters     state  \n",
       "16                8  COMPLETE  \n",
       "32               10  COMPLETE  \n",
       "43               10  COMPLETE  \n",
       "42               10  COMPLETE  \n",
       "13                7  COMPLETE  \n",
       "38                7  COMPLETE  \n",
       "47               13  COMPLETE  \n",
       "12                7  COMPLETE  \n",
       "31                8  COMPLETE  \n",
       "11                8  COMPLETE  \n",
       "24                7  COMPLETE  \n",
       "21                7  COMPLETE  \n",
       "35                9  COMPLETE  \n",
       "41                7  COMPLETE  \n",
       "17               10  COMPLETE  \n",
       "9                 8  COMPLETE  \n",
       "37               15  COMPLETE  \n",
       "20                9  COMPLETE  \n",
       "45               12  COMPLETE  \n",
       "26               13  COMPLETE  \n",
       "34               12  COMPLETE  \n",
       "44               10  COMPLETE  \n",
       "49               14  COMPLETE  \n",
       "1                11  COMPLETE  \n",
       "22                6  COMPLETE  \n",
       "36               11  COMPLETE  \n",
       "30                6  COMPLETE  \n",
       "46               20  COMPLETE  \n",
       "33               11  COMPLETE  \n",
       "27                5  COMPLETE  \n",
       "48                9  COMPLETE  \n",
       "28                8  COMPLETE  \n",
       "15                5  COMPLETE  \n",
       "4                18  COMPLETE  \n",
       "19               12  COMPLETE  \n",
       "7                13  COMPLETE  \n",
       "5                15  COMPLETE  \n",
       "29                4  COMPLETE  \n",
       "40               16  COMPLETE  \n",
       "18                4  COMPLETE  \n",
       "0                 4  COMPLETE  \n",
       "23                3  COMPLETE  \n",
       "39                5  COMPLETE  \n",
       "2                15  COMPLETE  \n",
       "3                19  COMPLETE  \n",
       "10                2  COMPLETE  \n",
       "14                1  COMPLETE  \n",
       "6                 6  COMPLETE  \n",
       "8                10  COMPLETE  \n",
       "25                9  COMPLETE  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from __future__ import annotations\n",
    "from icarlearn.ensemble.splitvotingens import *\n",
    "from sklearn.metrics import *\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from optuna import Trial\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "def objective_cv(trial : Trial, X : pd.DataFrame, y : np.ndarray | pd.Series, random_state : int=42):\n",
    "    params = {\n",
    "        'learning_rate': trial.suggest_float(\"learning_rate\", 1e-3, 0.1, log=True),\n",
    "        'n_voters': trial.suggest_int('n_voters', 1, 20, step=1),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 60, 200, step=20),\n",
    "    }\n",
    "    gbm = sveLGBM(**params)\n",
    "    kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "    my_scorer = make_scorer(balanced_accuracy_score)\n",
    "    #my_scorer = make_scorer(geometric_mean_score)\n",
    "    scores = cross_val_score(gbm, X, y, scoring=my_scorer, cv=kf)\n",
    "    return np.mean(scores)\n",
    "\n",
    "savepath = '../pycaret'\n",
    "study = optuna.create_study(\n",
    "    study_name=f'svelgbm_{tissue}',\n",
    "    direction='maximize',\n",
    "    load_if_exists=True,\n",
    "    storage=f'sqlite:///{savepath}/sveLGBM_{tissue}_ba_cv.db'\n",
    "    )\n",
    "study.optimize(lambda trial: objective_cv(trial, df_X, df_y), n_trials=50)\n",
    "best_params = study.best_params\n",
    "print('Best Params:', best_params)\n",
    "df = study.trials_dataframe()\n",
    "df.to_csv(os.path.join(f'sveLGBM_{tissue}_hypersearch_ba_cv.csv'))\n",
    "df.sort_values('value', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Test the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0        15994\n",
       "1         1242\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(learning_rate=0.09849119540851549, n_estimators=160, verbose=-1)\n",
      "Classification with sveLGBM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90ab6a2b2a974e1ca3f71d2acbe78ccb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "5-fold:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>measure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ROC-AUC</th>\n",
       "      <td>0.9580.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.9160.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BA</th>\n",
       "      <td>0.8900.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Specificity</th>\n",
       "      <td>0.9200.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sensitivity</th>\n",
       "      <td>0.8590.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G-mean</th>\n",
       "      <td>0.8890.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCC</th>\n",
       "      <td>0.5880.009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 measure\n",
       "ROC-AUC      0.9580.005\n",
       "Accuracy     0.9160.002\n",
       "BA           0.8900.009\n",
       "Specificity  0.9200.003\n",
       "Sensitivity  0.8590.019\n",
       "G-mean       0.8890.009\n",
       "MCC          0.5880.009"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from icarlearn.ensemble.splitvotingens import sveLGBM\n",
    "from icarlearn.validation.crossvalidate import skfold_cv\n",
    "from imblearn.metrics import specificity_score, geometric_mean_score\n",
    "\n",
    "from sklearn.metrics import *\n",
    "myscorer = { 'ROC-AUC':      (roc_auc_score, {'multi_class':'ovr', 'average':'macro'}),\n",
    "             'Accuracy'  :   (accuracy_score , {}),\n",
    "             'BA'  :         (balanced_accuracy_score , {}),\n",
    "             'Specificity' : (specificity_score, {'pos_label': 1}),\n",
    "             'Sensitivity' : (recall_score   , {'pos_label': 1}),\n",
    "             'G-mean' :      (geometric_mean_score   , {'pos_label': 1}),\n",
    "             'MCC' :         (matthews_corrcoef, {}), \n",
    "            }\n",
    "clf = sveLGBM(**study.best_params)\n",
    "df_scores, scores, predictions = skfold_cv(df_X, df_y, clf, n_splits=5, seed=0, scorer=myscorer, show_progress=True, verbose=True)\n",
    "df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrrr}\n",
      "\\toprule\n",
      " & boosting_type & learning_rate & n_estimators & n_voters & BA \\\\\n",
      "\\midrule\n",
      "44 & gbdt & 0.098461 & 200 & 8 & 0.892022 \\\\\n",
      "33 & gbdt & 0.081512 & 200 & 8 & 0.890714 \\\\\n",
      "43 & gbdt & 0.049017 & 200 & 8 & 0.888816 \\\\\n",
      "34 & gbdt & 0.079823 & 200 & 7 & 0.887190 \\\\\n",
      "23 & gbdt & 0.065070 & 140 & 13 & 0.886479 \\\\\n",
      "48 & gbdt & 0.045185 & 180 & 9 & 0.886413 \\\\\n",
      "35 & gbdt & 0.076854 & 200 & 7 & 0.886389 \\\\\n",
      "21 & gbdt & 0.050629 & 160 & 9 & 0.886107 \\\\\n",
      "49 & gbdt & 0.057144 & 200 & 8 & 0.886095 \\\\\n",
      "37 & gbdt & 0.077908 & 200 & 7 & 0.886046 \\\\\n",
      "32 & gbdt & 0.034572 & 180 & 11 & 0.885119 \\\\\n",
      "22 & gbdt & 0.039571 & 180 & 12 & 0.884895 \\\\\n",
      "41 & gbdt & 0.051064 & 200 & 7 & 0.884837 \\\\\n",
      "29 & gbdt & 0.030759 & 180 & 10 & 0.884531 \\\\\n",
      "6 & gbdt & 0.065527 & 100 & 12 & 0.884275 \\\\\n",
      "0 & gbdt & 0.031088 & 180 & 11 & 0.884031 \\\\\n",
      "31 & gbdt & 0.031174 & 180 & 10 & 0.883759 \\\\\n",
      "15 & gbdt & 0.041630 & 160 & 9 & 0.883406 \\\\\n",
      "24 & gbdt & 0.040524 & 140 & 15 & 0.882707 \\\\\n",
      "20 & gbdt & 0.099690 & 60 & 10 & 0.881841 \\\\\n",
      "2 & gbdt & 0.085391 & 200 & 6 & 0.881601 \\\\\n",
      "18 & gbdt & 0.056074 & 100 & 16 & 0.880590 \\\\\n",
      "19 & gbdt & 0.024005 & 180 & 9 & 0.880420 \\\\\n",
      "46 & gbdt & 0.073471 & 200 & 6 & 0.879457 \\\\\n",
      "39 & dart & 0.063560 & 200 & 7 & 0.875153 \\\\\n",
      "26 & dart & 0.065108 & 180 & 13 & 0.874942 \\\\\n",
      "47 & gbdt & 0.098334 & 180 & 5 & 0.874021 \\\\\n",
      "42 & gbdt & 0.060848 & 160 & 5 & 0.872442 \\\\\n",
      "25 & gbdt & 0.018323 & 160 & 8 & 0.872072 \\\\\n",
      "11 & gbdt & 0.015863 & 100 & 11 & 0.869731 \\\\\n",
      "8 & dart & 0.029505 & 180 & 12 & 0.866041 \\\\\n",
      "3 & dart & 0.037974 & 200 & 17 & 0.865953 \\\\\n",
      "7 & dart & 0.065467 & 80 & 6 & 0.863830 \\\\\n",
      "9 & dart & 0.050532 & 140 & 18 & 0.863715 \\\\\n",
      "28 & gbdt & 0.047467 & 160 & 4 & 0.861209 \\\\\n",
      "36 & dart & 0.075194 & 200 & 5 & 0.860882 \\\\\n",
      "13 & gbdt & 0.025414 & 60 & 14 & 0.860572 \\\\\n",
      "16 & gbdt & 0.012535 & 100 & 14 & 0.859903 \\\\\n",
      "17 & gbdt & 0.005336 & 160 & 12 & 0.859829 \\\\\n",
      "1 & gbdt & 0.010381 & 200 & 6 & 0.858121 \\\\\n",
      "27 & gbdt & 0.007571 & 140 & 19 & 0.848071 \\\\\n",
      "40 & gbdt & 0.086827 & 200 & 3 & 0.837165 \\\\\n",
      "30 & gbdt & 0.003034 & 120 & 16 & 0.832801 \\\\\n",
      "10 & gbdt & 0.001386 & 80 & 14 & 0.825037 \\\\\n",
      "14 & gbdt & 0.005514 & 120 & 20 & 0.825036 \\\\\n",
      "5 & gbdt & 0.003636 & 140 & 8 & 0.807176 \\\\\n",
      "38 & gbdt & 0.081153 & 200 & 2 & 0.805407 \\\\\n",
      "4 & dart & 0.018938 & 160 & 4 & 0.801913 \\\\\n",
      "12 & gbdt & 0.094523 & 120 & 1 & 0.745551 \\\\\n",
      "45 & dart & 0.001126 & 200 & 8 & 0.500000 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#df = pd.read_csv(f'velgbm_{tissue}_hypersearch_mcc_ba_2.csv').sort_values(['values_1', 'values_0'], ascending=[False, False]).rename(columns={'values_0': 'BA', 'values_1': 'MCC'})\n",
    "df = pd.read_csv(f'velgbm_Kidney_hypersearch_ba_cv.csv').sort_values('value', ascending=False).rename(columns={'value': 'BA'})\n",
    "df.columns = df.columns.str.replace(r'params_', '')\n",
    "selcolumns = ['boosting_type',\t'learning_rate',\t'n_estimators',\t'n_voters', 'BA']\n",
    "stds = df.std(numeric_only=True)\n",
    "#df['BA+MCC'] = df.apply(lambda x: x.BA * stds.loc['BA'] + x.MCC * stds.loc['MCC'], axis=1)\n",
    "#df['BA+MCC'] = df.apply(lambda x: x.BA  + x.MCC , axis=1)\n",
    "print(df[selcolumns].sort_values('BA', ascending=False).to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load exisiting study from DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The runtime optuna version 3.6.1 is no longer compatible with the table schema (set up by optuna 3.1.1). Please execute `$ optuna storage upgrade --storage $STORAGE_URL` for upgrading the storage.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01moptuna\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m study \u001b[38;5;241m=\u001b[39m \u001b[43moptuna\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_study\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvelgbm_Kidney\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msqlite:///../../results/veLGBM_Kidney_ba_cv.db\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/optuna/_convert_positional_args.py:83\u001b[0m, in \u001b[0;36mconvert_positional_args.<locals>.converter_decorator.<locals>.converter_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m     78\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() got multiple values for arguments \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mduplicated_kwds\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     79\u001b[0m     )\n\u001b[1;32m     81\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mupdate(inferred_kwargs)\n\u001b[0;32m---> 83\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/optuna/study/study.py:1353\u001b[0m, in \u001b[0;36mload_study\u001b[0;34m(study_name, storage, sampler, pruner)\u001b[0m\n\u001b[1;32m   1347\u001b[0m     study_name \u001b[38;5;241m=\u001b[39m study_names[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1348\u001b[0m     _logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m   1349\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStudy name was omitted but trying to load \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstudy_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m because that was the only \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1350\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstudy found in the storage.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1351\u001b[0m     )\n\u001b[0;32m-> 1353\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mStudy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstudy_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msampler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpruner\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpruner\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/optuna/study/study.py:81\u001b[0m, in \u001b[0;36mStudy.__init__\u001b[0;34m(self, study_name, storage, sampler, pruner)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     75\u001b[0m     study_name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     78\u001b[0m     pruner: pruners\u001b[38;5;241m.\u001b[39mBasePruner \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     79\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstudy_name \u001b[38;5;241m=\u001b[39m study_name\n\u001b[0;32m---> 81\u001b[0m     storage \u001b[38;5;241m=\u001b[39m \u001b[43mstorages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_storage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m     study_id \u001b[38;5;241m=\u001b[39m storage\u001b[38;5;241m.\u001b[39mget_study_id_from_name(study_name)\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_study_id \u001b[38;5;241m=\u001b[39m study_id\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/optuna/storages/__init__.py:43\u001b[0m, in \u001b[0;36mget_storage\u001b[0;34m(storage)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m storage\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mredis\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     40\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     41\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRedisStorage is removed at Optuna v3.1.0. Please use JournalRedisStorage instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     42\u001b[0m         )\n\u001b[0;32m---> 43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _CachedStorage(\u001b[43mRDBStorage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(storage, RDBStorage):\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _CachedStorage(storage)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/optuna/storages/_rdb/storage.py:233\u001b[0m, in \u001b[0;36mRDBStorage.__init__\u001b[0;34m(self, url, engine_kwargs, skip_compatibility_check, heartbeat_interval, grace_period, failed_trial_callback, skip_table_creation)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_version_manager \u001b[38;5;241m=\u001b[39m _VersionManager(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoped_session)\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m skip_compatibility_check:\n\u001b[0;32m--> 233\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_version_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_table_schema_compatibility\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/optuna/storages/_rdb/storage.py:1107\u001b[0m, in \u001b[0;36m_VersionManager.check_table_schema_compatibility\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1102\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1103\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1104\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease try updating optuna to the latest version by `$ pip install -U optuna`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1105\u001b[0m     )\n\u001b[0;32m-> 1107\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(message)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The runtime optuna version 3.6.1 is no longer compatible with the table schema (set up by optuna 3.1.1). Please execute `$ optuna storage upgrade --storage $STORAGE_URL` for upgrading the storage."
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "study = optuna.load_study(study_name='velgbm_Kidney', storage=\"sqlite:///../../results/veLGBM_Kidney_ba_cv.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrllllrrrl}\n",
      "\\toprule\n",
      " & Unnamed: 0 & number & value & datetime_start & datetime_complete & duration & params_boosting_type & params_learning_rate & params_n_estimators & params_n_voters & state \\\\\n",
      "\\midrule\n",
      "37 & 37 & 37 & 0.893151 & 2024-06-05 11:48:54.638670 & 2024-06-05 11:50:51.129284 & 0 days 00:01:56.490614 & gbdt & 0.094505 & 200 & 13 & COMPLETE \\\\\n",
      "15 & 15 & 15 & 0.891459 & 2024-06-05 11:16:36.759285 & 2024-06-05 11:17:48.725832 & 0 days 00:01:11.966547 & gbdt & 0.098300 & 140 & 10 & COMPLETE \\\\\n",
      "44 & 44 & 44 & 0.890954 & 2024-06-05 12:01:09.467990 & 2024-06-05 12:03:01.279431 & 0 days 00:01:51.811441 & gbdt & 0.076452 & 200 & 12 & COMPLETE \\\\\n",
      "43 & 43 & 43 & 0.890826 & 2024-06-05 11:59:18.529245 & 2024-06-05 12:01:09.439684 & 0 days 00:01:50.910439 & gbdt & 0.075168 & 200 & 12 & COMPLETE \\\\\n",
      "41 & 41 & 41 & 0.890602 & 2024-06-05 11:55:19.637376 & 2024-06-05 11:57:14.427060 & 0 days 00:01:54.789684 & gbdt & 0.078591 & 200 & 13 & COMPLETE \\\\\n",
      "33 & 33 & 33 & 0.890241 & 2024-06-05 11:41:24.249171 & 2024-06-05 11:43:10.811969 & 0 days 00:01:46.562798 & gbdt & 0.098020 & 180 & 13 & COMPLETE \\\\\n",
      "31 & 31 & 31 & 0.889936 & 2024-06-05 11:38:39.300887 & 2024-06-05 11:40:07.620982 & 0 days 00:01:28.320095 & gbdt & 0.059095 & 160 & 11 & COMPLETE \\\\\n",
      "34 & 34 & 34 & 0.889739 & 2024-06-05 11:43:10.839798 & 2024-06-05 11:45:06.900256 & 0 days 00:01:56.060458 & gbdt & 0.085756 & 200 & 13 & COMPLETE \\\\\n",
      "22 & 22 & 22 & 0.889298 & 2024-06-05 11:25:26.230130 & 2024-06-05 11:26:54.179467 & 0 days 00:01:27.949337 & gbdt & 0.063759 & 180 & 9 & COMPLETE \\\\\n",
      "30 & 30 & 30 & 0.889146 & 2024-06-05 11:37:07.850616 & 2024-06-05 11:38:39.277972 & 0 days 00:01:31.427356 & gbdt & 0.054934 & 160 & 12 & COMPLETE \\\\\n",
      "36 & 36 & 36 & 0.889028 & 2024-06-05 11:46:56.479716 & 2024-06-05 11:48:54.613399 & 0 days 00:01:58.133683 & gbdt & 0.076796 & 200 & 14 & COMPLETE \\\\\n",
      "23 & 23 & 23 & 0.888994 & 2024-06-05 11:26:54.212821 & 2024-06-05 11:28:13.256683 & 0 days 00:01:19.043862 & gbdt & 0.065602 & 160 & 9 & COMPLETE \\\\\n",
      "42 & 42 & 42 & 0.888759 & 2024-06-05 11:57:14.453339 & 2024-06-05 11:59:18.504381 & 0 days 00:02:04.051042 & gbdt & 0.076634 & 200 & 16 & COMPLETE \\\\\n",
      "40 & 40 & 40 & 0.888419 & 2024-06-05 11:53:50.416004 & 2024-06-05 11:55:19.609359 & 0 days 00:01:29.193355 & gbdt & 0.044127 & 180 & 10 & COMPLETE \\\\\n",
      "4 & 4 & 4 & 0.888175 & 2024-06-05 11:00:34.985200 & 2024-06-05 11:02:04.447899 & 0 days 00:01:29.462699 & gbdt & 0.088891 & 140 & 15 & COMPLETE \\\\\n",
      "39 & 39 & 39 & 0.887998 & 2024-06-05 11:52:23.815915 & 2024-06-05 11:53:50.393635 & 0 days 00:01:26.577720 & gbdt & 0.098960 & 140 & 14 & COMPLETE \\\\\n",
      "49 & 49 & 49 & 0.887826 & 2024-06-05 12:08:21.056280 & 2024-06-05 12:10:25.153124 & 0 days 00:02:04.096844 & gbdt & 0.057674 & 200 & 16 & COMPLETE \\\\\n",
      "11 & 11 & 11 & 0.886745 & 2024-06-05 11:09:23.401873 & 2024-06-05 11:11:12.844978 & 0 days 00:01:49.443105 & gbdt & 0.059871 & 180 & 15 & COMPLETE \\\\\n",
      "47 & 47 & 47 & 0.886566 & 2024-06-05 12:05:43.967330 & 2024-06-05 12:07:40.729782 & 0 days 00:01:56.762452 & gbdt & 0.049777 & 200 & 14 & COMPLETE \\\\\n",
      "29 & 29 & 29 & 0.886259 & 2024-06-05 11:35:41.090319 & 2024-06-05 11:37:07.825876 & 0 days 00:01:26.735557 & gbdt & 0.042902 & 180 & 9 & COMPLETE \\\\\n",
      "32 & 32 & 32 & 0.885557 & 2024-06-05 11:40:07.648602 & 2024-06-05 11:41:24.216740 & 0 days 00:01:16.568138 & gbdt & 0.052158 & 140 & 11 & COMPLETE \\\\\n",
      "0 & 0 & 0 & 0.885387 & 2024-06-05 10:55:36.431230 & 2024-06-05 10:57:27.994247 & 0 days 00:01:51.563017 & gbdt & 0.049584 & 180 & 15 & COMPLETE \\\\\n",
      "24 & 24 & 24 & 0.885176 & 2024-06-05 11:28:13.283267 & 2024-06-05 11:29:31.878620 & 0 days 00:01:18.595353 & gbdt & 0.048817 & 160 & 9 & COMPLETE \\\\\n",
      "21 & 21 & 21 & 0.884109 & 2024-06-05 11:23:30.056208 & 2024-06-05 11:25:26.201734 & 0 days 00:01:56.145526 & gbdt & 0.070336 & 180 & 17 & COMPLETE \\\\\n",
      "12 & 12 & 12 & 0.884045 & 2024-06-05 11:11:12.878465 & 2024-06-05 11:12:54.888003 & 0 days 00:01:42.009538 & gbdt & 0.060010 & 160 & 16 & COMPLETE \\\\\n",
      "13 & 13 & 13 & 0.883496 & 2024-06-05 11:12:54.911635 & 2024-06-05 11:15:03.241229 & 0 days 00:02:08.329594 & gbdt & 0.082780 & 200 & 17 & COMPLETE \\\\\n",
      "27 & 27 & 27 & 0.883429 & 2024-06-05 11:32:46.372520 & 2024-06-05 11:34:15.827032 & 0 days 00:01:29.454512 & gbdt & 0.036259 & 160 & 12 & COMPLETE \\\\\n",
      "14 & 14 & 14 & 0.883002 & 2024-06-05 11:15:03.263901 & 2024-06-05 11:16:36.734840 & 0 days 00:01:33.470939 & gbdt & 0.043999 & 160 & 13 & COMPLETE \\\\\n",
      "45 & 45 & 45 & 0.882917 & 2024-06-05 12:03:01.301653 & 2024-06-05 12:03:57.041232 & 0 days 00:00:55.739579 & gbdt & 0.071196 & 80 & 15 & COMPLETE \\\\\n",
      "19 & 19 & 19 & 0.881732 & 2024-06-05 11:21:11.873049 & 2024-06-05 11:22:28.227983 & 0 days 00:01:16.354934 & gbdt & 0.034591 & 140 & 11 & COMPLETE \\\\\n",
      "35 & 35 & 35 & 0.880509 & 2024-06-05 11:45:06.928916 & 2024-06-05 11:46:56.458933 & 0 days 00:01:49.530017 & dart & 0.099165 & 200 & 13 & COMPLETE \\\\\n",
      "46 & 46 & 46 & 0.880259 & 2024-06-05 12:03:57.072919 & 2024-06-05 12:05:43.944116 & 0 days 00:01:46.871197 & dart & 0.080275 & 200 & 12 & COMPLETE \\\\\n",
      "26 & 26 & 26 & 0.878634 & 2024-06-05 11:31:14.870915 & 2024-06-05 11:32:46.346121 & 0 days 00:01:31.475206 & dart & 0.070387 & 200 & 8 & COMPLETE \\\\\n",
      "38 & 38 & 38 & 0.876939 & 2024-06-05 11:50:51.154555 & 2024-06-05 11:52:23.789150 & 0 days 00:01:32.634595 & dart & 0.081331 & 180 & 11 & COMPLETE \\\\\n",
      "28 & 28 & 28 & 0.875443 & 2024-06-05 11:34:15.858102 & 2024-06-05 11:35:41.067117 & 0 days 00:01:25.209015 & gbdt & 0.021234 & 180 & 7 & COMPLETE \\\\\n",
      "18 & 18 & 18 & 0.872098 & 2024-06-05 11:20:21.250389 & 2024-06-05 11:21:11.849943 & 0 days 00:00:50.599554 & dart & 0.051942 & 100 & 10 & COMPLETE \\\\\n",
      "17 & 17 & 17 & 0.869416 & 2024-06-05 11:19:09.954100 & 2024-06-05 11:20:21.222264 & 0 days 00:01:11.268164 & gbdt & 0.027927 & 140 & 6 & COMPLETE \\\\\n",
      "48 & 48 & 48 & 0.869126 & 2024-06-05 12:07:40.757239 & 2024-06-05 12:08:21.032810 & 0 days 00:00:40.275571 & gbdt & 0.031879 & 60 & 12 & COMPLETE \\\\\n",
      "1 & 1 & 1 & 0.868272 & 2024-06-05 10:57:28.036931 & 2024-06-05 10:58:03.917219 & 0 days 00:00:35.880288 & gbdt & 0.028757 & 60 & 10 & COMPLETE \\\\\n",
      "2 & 2 & 2 & 0.867393 & 2024-06-05 10:58:03.943144 & 2024-06-05 10:59:05.800986 & 0 days 00:01:01.857842 & dart & 0.097710 & 80 & 20 & COMPLETE \\\\\n",
      "9 & 9 & 9 & 0.865516 & 2024-06-05 11:06:23.253566 & 2024-06-05 11:07:21.182252 & 0 days 00:00:57.928686 & gbdt & 0.014628 & 100 & 12 & COMPLETE \\\\\n",
      "3 & 3 & 3 & 0.864723 & 2024-06-05 10:59:05.824959 & 2024-06-05 11:00:34.964696 & 0 days 00:01:29.139737 & dart & 0.022029 & 200 & 8 & COMPLETE \\\\\n",
      "7 & 7 & 7 & 0.863132 & 2024-06-05 11:04:12.898727 & 2024-06-05 11:05:01.378222 & 0 days 00:00:48.479495 & gbdt & 0.037196 & 60 & 19 & COMPLETE \\\\\n",
      "25 & 25 & 25 & 0.858484 & 2024-06-05 11:29:31.913448 & 2024-06-05 11:31:14.844163 & 0 days 00:01:42.930715 & gbdt & 0.063340 & 180 & 4 & COMPLETE \\\\\n",
      "6 & 6 & 6 & 0.853296 & 2024-06-05 11:02:54.607868 & 2024-06-05 11:04:12.878780 & 0 days 00:01:18.270912 & dart & 0.007230 & 140 & 14 & COMPLETE \\\\\n",
      "16 & 16 & 16 & 0.841683 & 2024-06-05 11:17:48.749369 & 2024-06-05 11:19:09.929881 & 0 days 00:01:21.180512 & gbdt & 0.098819 & 120 & 3 & COMPLETE \\\\\n",
      "8 & 8 & 8 & 0.837894 & 2024-06-05 11:05:01.403661 & 2024-06-05 11:06:23.226002 & 0 days 00:01:21.822341 & dart & 0.013705 & 120 & 20 & COMPLETE \\\\\n",
      "10 & 10 & 10 & 0.807671 & 2024-06-05 11:07:21.204818 & 2024-06-05 11:09:23.377896 & 0 days 00:02:02.173078 & gbdt & 0.089129 & 160 & 2 & COMPLETE \\\\\n",
      "20 & 20 & 20 & 0.780058 & 2024-06-05 11:22:28.248833 & 2024-06-05 11:23:30.032032 & 0 days 00:01:01.783199 & gbdt & 0.007526 & 120 & 5 & COMPLETE \\\\\n",
      "5 & 5 & 5 & 0.500000 & 2024-06-05 11:02:04.473791 & 2024-06-05 11:02:54.579557 & 0 days 00:00:50.105766 & gbdt & 0.001175 & 100 & 7 & COMPLETE \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(pd.read_csv(\"velgbm_Kidney_hypersearch_ba_cv.csv\").replace({'':'','':'','':'','':''})sort_values('value', ascending=False).to_latex())"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4549240,
     "sourceId": 7775239,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
